---
title: 'Trabalho Final - Avaliação de Algoritmos em um Problema de Otimização de
   Roteiros de Viagem'
author: "Equipe 04"
date: "03 de Julho de 2017"
output:
  pdf_document:
    citation_package: natbib
    fig_caption: yes
  html_document: default
  word_document: default
header-includes:
- \usepackage{fancyhdr}
- \usepackage[utf8]{inputenc}
- \pagestyle{fancy}
- \fancyfoot[CO,CE]{EEE933 - Planejamento e Análise de Experimentos}
- \fancyfoot[LE,RO]{\thepage}
- \usepackage{booktabs}
- \usepackage{graphicx}
csl: ieee.csl
bibliography: bibliography.bib
urlcolor: blue
---  
Coordenador: Gustavo Vieira    
Relator: Bernardo Marques   
Verificador: Danny Tonidandel   
Monitor: Alessandro Cardoso

```{r setup,include=FALSE, results='hide',warning=FALSE,echo=FALSE}
if (!require(readr, quietly = TRUE)){
  install.packages("readr")
}
if (!require(car, quietly = TRUE)){
  install.packages("car")
}
if (!require(lmtest, quietly = TRUE)){
  install.packages("lmtest")
}

source('calcN.R')
library(car)
library(lmtest)

```

# Sumário
...

# 1. Descrição do Problema

As ferramentas atuais para planejamento de viagens permitem que usuários busquem passagens e hotéis e construam seu próprio itinerário, mas não oferecem suporte para viagens com flexibilidade nas datas ou na ordenação de destinos. Para solucionar esse problema, foi proposto um novo sistema que busca as melhores combinações de passagens e hotéis para uma viagem, minimizando o custo e tempo de transporte. O sistema busca otimizar roteiros com datas flexíveis e não requer uma ordem fixa dos destinos, de forma que considera todas as possíveis configurações que atendem as especificações do usuário. Dessa forma, oferece boas opções de itinerários para viagens com esforço do usuário muito menor, representando uma melhoria significativa na experiência de planejamento de viagens.

O conjunto de restrições do problema considera datas inicial e final, datas específicas para cada destino, ordenação dos destinos e características das acomodações e transportes. Pode ser considerado uma aplicação multiobjetivo do problema do caixeiro viajante com janelas de tempo e dependência temporal.

Para realizar a otimização de roteiros, foi utilizado um algoritmo de colônia de formigas [@cite]. Uma melhoria para o algoritmo utilizando busca local foi proposta. O objetivo do trabalho é comparar os algoritmos e determinar se a melhoria proposta é melhor para solucionar o problema, avaliando tanto o tempo gasto na otimização e a qualidade do conjunto de soluções encontrado. Assim, as perguntas a serem respondidas são:

- TODO
- TODO

No entanto, o tamanho do roteiro a ser avaliado também influencia esses resultados. Assim, é necessário considerar o tamanho da instância como uma covariável do problema. Para lidar com isso, serão utilizadas técnicas de blocagem, e também exploradas técnicas estatísticas de análise de covariância.

```{r,results='show',warning=FALSE,echo=FALSE}
## EXPERIMENTAL DEFINITIONS
v_alpha = 0.05
v_beta = 0.20
v_power = 1-v_beta
v_delta = 0.25
v_dTime = 1
v_dQuality = 1
```
Os parâmetros experimentais desejados são:

* Nível de significância: $\alpha = `r v_alpha`$;

* Tamanho de efeito de interesse prático: $d^{\star}_time = d^{\star}_quality = `r v_dTime`$;

* Potência desejada: $(1- \beta) = \pi \geq `r v_power`$.


TODO: explicar melhor o problema

# 2. Planejamento Experimental

Os dados experimentais do problema foram obtidos através de simulações. Foram geradas instâncias do problema de diferentes tamanhos. Para cada uma delas, cada algoritmo foi aplicado 8 vezes, e os resultados registrados. A ordem das instâncias geradas e da aplicação dos algoritmos foi aleatorizada de maneira a bloquear possíveis efeitos de ordem.

Nos experimentos, foi medido o tempo gasto na execução de cada algoritmo. Para minimizar a influência de outros processos do sistema, a execução foi limitada a um único núcleo do processador, com prioridade de execução alta.

Cada algoritmo de otimização produz como resultado um conjunto de soluções. A qualidade desse conjunto é medida através do Hipervolume [@cite] do conjunto na fronteira de Pareto, considerando como referência o ponto da solução Nadir na fronteira de Pareto (isto é, a pior solução teórica). Para cada instância avaliada, um novo ponto de referência é calculado através de uma heurística.

O método de Hipervolume é bastante sensível ao ponto de referência definido [@cite]. Sendo assim, a qualidade medida entre diferentes instâncias não tem significado quando comparadas entre si. No entanto, a métrica é eficiente para comparar a qualidade de diferentes conjuntos de solução encontrados no mesmo ponto. Sendo assim, é necessário avaliar a qualidade relativa das soluções em cada instância, e não o seu valor absoluto.

## 2.1 Definição do Tamanho Amostral

O tamanho amostral do problema foi cálculado a partir dos requisitos experimentais estabelecidos. Uma vez que o tamanho de efeito de interesse prático foi definido em relação a variância, não era necessário conhecer a variância dos dados previamente. Assume-se que a variância entre os diferentes algorítmos é igual.

Dessa forma, o tamanho amostral do experimento foi calculado através da equação:

$$n = 2 \left( \frac{1}{d^{\star}_t}\right)^{2}(t_{\alpha/2}+t_{\beta})^{2} \,,$$
, solucionada iterativamente.

## 2.2 Análise de Variância com Blocagem

Para a avaliar existência de diferenças significativas entre os dois parâmetros, será utilizado o teste estatístico ANOVA.

Essa técnica analisa médias e variâncias de observações de diferentes grupos para verificar se existe diferença estatístixa significativa entre as médias desses grupos. Assim, generaliza o teste t para mais de dois grupos, permitindo que sejam comparados simultâneamente [@Campelo2015-01], [@MontgomeryRunger2011]. Em outras palavras, a análise de variância é utilizada quando se quer decidir se os níveis apresentam médias diferentes em relação é uma média global $\mu$. As diferenças entre as médias dos níveis e a média global é  $\tau_i$ $\forall \  i$. 

Vale ressaltar que a técnica é restrita apenas à indicação de existência ou não de diferenças entre os níveis avaliados, sem indicar quais níveis seriam diferentes. Além disso, quando a análise de variância tem como resultado um indicativo de refutação da hipótese nula $\eqref{eq:01}$ é que podem ser evidenciados os indícios de diferenças entre os níveis.


\begin{equation}
\left\{\begin{array}{rc}
H_{0}:& \tau_i = 0, \ \ \ \forall i\\
H_{1}:& \exists \ \ \tau_i \neq 0
\end{array}\right.
\label{eq:01}
\end{equation}

Esta etapa foi considerada como uma primeira verificação ao questionamento deste estudo por apresentar uma abordagem que pode minimizar o custo de coleta de amostras menor do que o teste de comparações múltiplas discutido na Seção 2.2. Portanto, caso não seja detectada alguma diferenças entre os níveis, as comparações múltiplas são dispensáveis, o que reduz o custo do experimento.


## 2.3 Comparações Múltiplas

Caso a análise ANOVA identifique a existência de diferenças entre os parâmetros analisados nos algoritmos, deve-se proceder com testes de comparação múltiplas. As comparações serão realizadas em relação ao algoritmo _ACO_, de maneira a verificar se a outra alternativa proposta é melhor.
Desta forma, caso a análise de variância indique a existência de diferenças entre os níveis, será aplicado o teste de comparações múltiplas um-contra-todos (one-vs-all) de _Dunnett_, onde o _ACO com busca local_ será confrontado com o algoritmo _ACO_.

Para realizar o teste de comparações múltiplas, deve-se manter o controle sobre os erros do tipo-$I$ em cada comparação de maneira com que ele não se acumule a cada teste sucessivo. Assim, os valores de $\alpha$ são corrigidos para cada teste através do método de correção de Bonferroni $\eqref{eq:02}$:

\begin{equation}
\alpha_{adj} = \frac{\alpha_{família}}{K} \,,
\label{eq:02}
\end{equation}

no qual $K=1$ consiste no número de comparações a serem feitas que no caso do teste um-contra-todos de _Dunnett_. O número de comparações nesse caso é dado pela Equação \eqref{eq:03}:

\begin{equation}
K=a-1  \,;
\label{eq:03}
\end{equation}.


## 2.4 Análise de Covariância (ANCOVA)

A análise de covariância é uma técnica $-$ assim como a blocagem ou pareamento (em testes-t) $-$ bastante útil para a melhora da precisão de um experimento [@montgomery1984design]. Em diversos aspectos é similar à análise de variância (ANOVA), porém permite ter controle sobre a influência do covariante nas variâveis dependentes. 


A covariável complementa o controle local e, obviamente, necessita estar correlacionada com a variável de resposta para que se possa fazer uso de tal análise. E quando a análise de variância é realizada com uma ou mais covariáveis, é usual chamar a análise de ANCOVA.

Na ANCOVA a variável dependente é contínua (e.g. tempo, velocidade, etc.), enquanto que a variável independente é normalmente categória (e.g. "masculino/feminino", "fumante/não-fumante" etc. ). A análise de variância, por sua vez, poderá converter-se na ANCOVA quando for adicionado um covariante, que consiste em outra variável, que pode ser tanto categórica quanto contínua. 

Existem aliás, duas razões principais para sair-se da ANOVA e passar a ser considerada a análise de covarância, i.e., razões técnicas para adicionar um covariante, quais sejam:

* Reduzir fatores de variabilidade inter-grupos, ou alcançar um nível maior de entendimento a partir da variância desconhecida;

* Isolar o efeito que ocorre quando o controle experimental não permite que o experimentador elimine, de maneira razoável, explicações alternativas para uma relação observada entre variáveis independentes e dependentes, o que é chamado de "confusão" _confounding_. Em outras palavras, esta variável é algo que pode estar influenciando o experimento mas que não está, a principio, no modelo original, e é uma potencial fonte de viéses no experimento.

A ANCOVA, permite, portanto, um controle do erro experimental, aumentando sua precisão. Vale ressaltar que a técnica não é restrita apenas à indicação de existência ou não de diferenças entre os níveis avaliados.

Considerando um experimento com um fator e uma covariável, o modelo estatístico da análise de covariância pode ser estabelecido como [@MontgomeryRunger2011]:
\begin{equation}
y_{ij} = \mu + \tau_{i} + \beta (x_{ij}- \bar{x_{..}}) + \epsilon_{ij} \,,
\label{eq:001}
\end{equation}
em que:
$\mu$ é uma constante, $\tau_{i}$ é o efeito do i-ésimo "tratamento", $X_{ij}$ é o valor observado da covariável e $\bar{x_{..}}$ a média dos valores $x_{ij}$ (da covariável). Além disso, $\beta$ consiste no coeficiente de regressão linear entre a covariável $X$ e a variável de resposta $Y$, com $\beta \neq 0$ e $\epsilon_{ij}$ é uma componente aleatória de erro, com $i = 1, \ldots , a$ e $j = 1, \ldots , n$. Neste caso a relação deve ser linear. Vale ressaltar que este modelo pressupõe que a variável de resposta e a covariável estão relacionadas linearmente. Para efeito de simplificação, contudo, a análise de covariância pode ser vista como uma análise "ajustada" de variância, e pode ser sumarizada na tabela $\eqref{{tab:001}}$:


\begin{table}[]
\centering
\caption{ANCOVA como um ``modelo ajustado'' da ANOVA.}
\label{tab:001}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}|l|c|c|c|c|@{}}
\toprule
\textbf{Fontes de variação} & \textbf{$\sum$ de quadrados}                                                                                        & \textbf{Graus de Lib} & \textbf{média quadrática}    & \textbf{$F_{0}$}                             \\ \midrule
\textbf{regressão}          & $(S_{xy}/S_{xx})$                                                                                                   & $1$                   &                              &                                              \\ \midrule
\textbf{Tratamentos}        & \begin{tabular}[c]{@{}c@{}}$SS'_{E}- SS_{E} - $\\ $(S_{xy})^{2}/S_{xx} - [E_{yy}-(E_{xy})^{2}/E_{xx}]$\end{tabular} & $a-1$                 & $\frac{SS'_{E}-SS_{E}}{a-1}$ & $\frac{1}{MS_{E}}\frac{SS'_{E}-SS_{E}}{a-1}$ \\ \midrule
\textbf{Erro}               & $SS_{E} = E_{yy}-(E_{xy})^{2}/E_{xx}$                                                                               & $a(n-1)-1$            & $\frac{SS_{E}}{a(n-1)-1}$    &                                              \\ \midrule
\textbf{Total}              & S\_\{yy\}                                                                                                           & $an-1$                &                              &                                              \\ \bottomrule
\end{tabular}%
}
\end{table}

em que:
\begin{eqnarray}
S_{yy} &=& \sum \limits_{i=1}^{a} \sum \limits_{j=1}^{n} {y_{ij}^{2}}- \frac{y_{..}^{2}}{an}  \,, \label{eq:002} \\
S_{xx} &=& \sum \limits_{i=1}^{a} \sum \limits_{j=1}^{n}  {x_{i.}^{2}}- \frac{x_{..}^{2}}{an} \,, \label{eq:003} \\
S_{xy} &=& \sum \limits_{i=1}^{a} \sum \limits_{j=1}^{n}  x_{ij}y_{ij} - \frac{(x_{..})(y_{..})}{an} \,, \label{eq:004} \\
T_{yy} &=& \frac{1}{n} \sum \limits_{i=1}^{a} {y_{i.}^{2}}- \frac{y_{..}^{2}}{an} \,, \label{eq:005} \\
T_{xx} &=& \frac{1}{n} \sum \limits_{i=1}^{a}  {x_{i.}^{2}}- \frac{x_{..}^{2}}{an} \,, \label{eq:006} \\
T_{xy} &=& \frac{1}{n}  \sum \limits_{i=1}^{a}  x_{i.}y_{i.} - \frac{(x_{..})(y_{..})}{an}     \,, \label{eq:007} \\
E_{yy} &=& S_{yy}-T_{yy}\,, \label{eq:008} \\
E_{xx} &=& S_{xx} - T_{xx}\,, \label{eq:009} \\
E_{xy} &=& S_{xy} - T_{xy}\,. \label{eq:010}
\end{eqnarray}

Assim, rejeita-se a hipótese nula $H_{0}: \beta=0$ se $F_{0}> F_{\alpha , 1, a(n-1)-1} \,.$


# 3. Resultados Análise Estatística

## 3.1 Tratamento e Validação dos Dados

Considerando o experimento realizado, foi criada uma rotina para validação dos dados obtidos e identificação de erros, onde o tempo de execução e valor de qualidade das respostas dos algoritmos na escala (((XXXXXlogarítma))) devem ser maior que $0$.

1. Tempo $> 0$

2. 0 > Qualidade $> 1$

Caso os valores de uma execução não atendam essas condições, ela seria descartada. No entanto, nenhuma das amostras apresentou tal problema.


## 3.2 Análise Exploratória dos Dados

```{r, echo=FALSE, fig.height=3.8, message=FALSE, warning=FALSE, results='show'}

v_data = readr::read_csv('results_fixed.csv')
v_data$algorithm = as.factor(v_data$algorithm)

v_dataSdRuns = aggregate(cbind(quality,time)~instance:algorithm:size,data=v_data, FUN=sd)

v_data = aggregate(cbind(quality,time,size,avgTransportations,avgAccommodations,destinations)~algorithm:instance, data=v_data, FUN=mean)

v_data$qualityRelative = v_data$quality/array(sapply(subset(v_data, algorithm=='ACO')$quality, function(v) return(rep(v,2))))

par(mfrow=c(1,2), mai=.4*c(2.5,1,1,1))

plot(x = (subset(v_data, algorithm=='ACO')$size),
     y = (subset(v_data, algorithm=='ACO')$time),
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "size",
     ylab = "Time")
points(x = (subset(v_data, algorithm=='ACO_Local')$size),
     y = (subset(v_data, algorithm=='ACO_Local')$time),
     cex  = 1,
     pch  = 18,
     col='blue')
legend("bottomright", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)

plot(x = (subset(v_data, algorithm=='ACO')$size),
     y = subset(v_data, algorithm=='ACO')$qualityRelative,
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "size",
     ylab = "Relative Quality")
points(x = (subset(v_data, algorithm=='ACO_Local')$size),
       y = subset(v_data, algorithm=='ACO_Local')$qualityRelative,
       cex  = 1,
       pch  = 18,
       col='blue')
legend("bottomleft", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)

```

A escala não permite ter uma visualização adequada dos dados. Assim, é aplicada uma transformação logaritmica na variável Size para solucionar esse problema.

```{r, echo=FALSE, fig.height=3.8, message=FALSE, warning=FALSE, results='show'}

par(mfrow=c(1,2), mai=.4*c(2.5,1,1,1))

plot(x = log(subset(v_data, algorithm=='ACO')$size),
     y = (subset(v_data, algorithm=='ACO')$time),
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "Time")
points(x = log(subset(v_data, algorithm=='ACO_Local')$size),
     y = (subset(v_data, algorithm=='ACO_Local')$time),
     cex  = 1,
     pch  = 18,
     col='blue')
legend("topleft", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)

plot(x = log(subset(v_data, algorithm=='ACO')$size),
     y = subset(v_data, algorithm=='ACO')$qualityRelative,
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "Relative Quality")
points(x = log(subset(v_data, algorithm=='ACO_Local')$size),
       y = subset(v_data, algorithm=='ACO_Local')$qualityRelative,
       cex  = 1,
       pch  = 18,
       col='blue')
legend("bottomleft", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)

```


Para normalizar a distribuição dos dados e obter uma relação linear entre a covariável e o tempo, foi aplicada uma transformação normal na variável de resposta Time.


```{r, echo=FALSE, fig.height=3.8, message=FALSE, warning=FALSE, results='show'}

par(mfrow=c(1,2), mai=.4*c(2.5,1,1,1))

plot(x = log(subset(v_data, algorithm=='ACO')$size),
     y = log(subset(v_data, algorithm=='ACO')$time),
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "Time")
points(x = log(subset(v_data, algorithm=='ACO_Local')$size),
     y = log(subset(v_data, algorithm=='ACO_Local')$time),
     cex  = 1,
     pch  = 18,
     col='blue')
legend("topleft", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)

plot(x = log(subset(v_data, algorithm=='ACO')$size),
     y = subset(v_data, algorithm=='ACO')$qualityRelative,
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "Relative Quality")
points(x = log(subset(v_data, algorithm=='ACO_Local')$size),
       y = subset(v_data, algorithm=='ACO_Local')$qualityRelative,
       cex  = 1,
       pch  = 18,
       col='blue')
legend("bottomleft", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)

```

Os resultados parecem indicar uma relação linear entre tempo e tamanho de problema (ambos em escala logarítmica). Além disso, a qualidade relativa das soluções parece não depender do tamanho. Finalmente, há indícios de que o algoritmo proposto é melhor que a alternativa tanto em quesitos de tempo quanto qualidade da solução encontrada.

## 3.2 Análise de Variância com Blocagem

### Tempo
Análise inicial sem considerar efeitos de tamanho do problema:
```{r, echo=FALSE, fig.height=3.8, fig.width=3.8, message=FALSE, warning=FALSE, results='show'}
summary.aov(aov(log(time)~algorithm, data=v_data))
```

Considerando efeitos:
```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}
# Time - simple model
v_modelAnovaTime <- aov(log(time)~algorithm+log(size), 
                        data = v_data)
summary.aov(v_modelAnovaTime)
v_r2 = summary.lm(v_modelAnovaTime)$r.square

par(mfrow=c(2,2), mai=.3*c(2.5,1,1,1))
plot(v_modelAnovaTime)

```


Considerando variável de interação entre tempo e tamanho do problema
```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}
# Time - iteraction effects
v_modelAnovaTime <- aov(log(time)~algorithm*log(size), 
                        data = v_data)
summary.aov(v_modelAnovaTime)
v_r2 = summary.lm(v_modelAnovaTime)$r.square

par(mfrow=c(2,2), mai=.3*c(2.5,1,1,1))
plot(v_modelAnovaTime)
```

### Qualidade da Solução
```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}
v_modelAnovaQuality <- aov((qualityRelative)~algorithm+log(size), 
                           data = v_data)
summary.aov(v_modelAnovaQuality)
v_r2 =summary.lm(v_modelAnovaQuality)$r.square

par(mfrow=c(2,2), mai=.3*c(2.5,1,1,1))
plot(v_modelAnovaQuality)

v_tTestQuality = t.test(qualityRelative~algorithm,
                        data=v_data,
                        mu = 0,
                        conf.level = 0.95, 
                        alternative = 'two.sided',
                        paired=TRUE
)
v_tTestQuality
```

```{r, echo=FALSE, fig.height=3.8, fig.width=3.8, message=FALSE, warning=FALSE, results='show'}

```

## 3.3 Análise de Covariância

# Geração do Conjunto de Dados
```{r, echo=FALSE, fig.height=3.8, fig.width=3.8, message=FALSE, warning=FALSE, results='show'}
v_data2 = v_data[seq(nrow(v_data)/2)*2 - rep(c(0,1),nrow(v_data)/4),]
```
TODO: plots do novo conjunto

# Tempo
```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}
v_data2 = v_data[seq(nrow(v_data)/2)*2 - rep(c(0,1),nrow(v_data)/4),]

# Time model fit
v_modelAncovaTime = aov(log(time)~algorithm+log(size), data=v_data2)
summary.aov(v_modelAncovaTime)
v_r2 = summary.lm(v_modelAncovaTime)$r.square

v_modelAncovaTime2 = aov(log(time)~log(size)+algorithm, data=v_data2)
summary.aov(v_modelAncovaTime2)
v_r2Model2 = summary.lm(v_modelAncovaTime2)$r.square

v_modelFitTime = lm(log(time)~log(size)+algorithm, data=v_data2)

plot(x = log(subset(v_data2, algorithm=='ACO')$size),
     y = log(subset(v_data2, algorithm=='ACO')$time),
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "Time")
points(x = log(subset(v_data2, algorithm=='ACO_Local')$size),
       y = log(subset(v_data2, algorithm=='ACO_Local')$time),
       cex  = 1,
       pch  = 18,
       col='blue')
legend("topleft", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)
abline(coef=c(v_modelFitTime$coefficients[1],v_modelFitTime$coefficients[2]), col='red')
abline(coef=c(v_modelFitTime$coefficients[1]+v_modelFitTime$coefficients[3],v_modelFitTime$coefficients[2]), col='blue')

par(mfrow=c(2,2), mai=.3*c(2.5,1,1,1))
plot(v_modelFitTime)
```


# Considerando efeito de iteração
```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}

v_modelAncovaTime2 = aov(log(time)~algorithm*log(size), data=v_data2)
summary.aov(v_modelAncovaTime2)
v_r2Model2 = summary.lm(v_modelAncovaTime2)$r.square

v_modelFitTime = lm(log(time)~log(size)*algorithm, data=v_data2)

plot(x = log(subset(v_data2, algorithm=='ACO')$size),
     y = log(subset(v_data2, algorithm=='ACO')$time),
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "Time")
points(x = log(subset(v_data2, algorithm=='ACO_Local')$size),
       y = log(subset(v_data2, algorithm=='ACO_Local')$time),
       cex  = 1,
       pch  = 18,
       col='blue')
legend("topleft", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)

abline(coef=c(v_modelFitTime$coefficients[1],v_modelFitTime$coefficients[2]), col='red')
abline(coef=c(v_modelFitTime$coefficients[1]+v_modelFitTime$coefficients[3],v_modelFitTime$coefficients[2]+v_modelFitTime$coefficients[4]), col='blue')
```


# Qualidade
```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}
v_modelAncovaTime = aov((qualityRelative)~algorithm+log(size), data=v_data2)
summary.aov(v_modelAncovaTime)
v_r2 = summary.lm(v_modelAncovaTime)$r.square

v_modelAncovaTime2 = aov((qualityRelative)~log(size)+algorithm, data=v_data2)
summary.aov(v_modelAncovaTime2)
v_r2Model2 = summary.lm(v_modelAncovaTime2)$r.square

v_modelFitTime = lm((qualityRelative)~log(size)+algorithm, data=v_data2)

plot(x = log(subset(v_data2, algorithm=='ACO')$size),
     y = (subset(v_data2, algorithm=='ACO')$qualityRelative),
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "Time")
points(x = log(subset(v_data2, algorithm=='ACO_Local')$size),
       y = (subset(v_data2, algorithm=='ACO_Local')$qualityRelative),
       cex  = 1,
       pch  = 18,
       col='blue')
legend("bottomright", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)
abline(coef=c(v_modelFitTime$coefficients[1],v_modelFitTime$coefficients[2]), col='red')
abline(coef=c(v_modelFitTime$coefficients[1]+v_modelFitTime$coefficients[3],v_modelFitTime$coefficients[2]), col='blue')

par(mfrow=c(2,2), mai=.3*c(2.5,1,1,1))
plot(v_modelFitTime)
```


# 4. Discussão e Conclusões

# Referências