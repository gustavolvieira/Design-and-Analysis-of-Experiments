---
title: 'Trabalho Final - Avaliação de Algoritmos em um Problema de Otimização de
   Roteiros de Viagem'
author: "Equipe 04"
date: "03 de Julho de 2017"
output:
  pdf_document:
    citation_package: natbib
    fig_caption: yes
  html_document: default
  word_document: default
header-includes:
- \usepackage{fancyhdr}
- \usepackage[utf8]{inputenc}
- \pagestyle{fancy}
- \fancyfoot[CO,CE]{EEE933 - Planejamento e Análise de Experimentos}
- \fancyfoot[LE,RO]{\thepage}
- \usepackage{booktabs}
- \usepackage{graphicx}
csl: ieee.csl
bibliography: bibliography.bib
urlcolor: blue
---  
Coordenador: Gustavo Vieira    
Relator: Bernardo Marques   
Verificador: Danny Tonidandel   
Monitor: Alessandro Cardoso

```{r setup,include=FALSE, results='hide',warning=FALSE,echo=FALSE}
if (!require(readr, quietly = TRUE)){
  install.packages("readr")
}
if (!require(car, quietly = TRUE)){
  install.packages("car")
}
if (!require(lmtest, quietly = TRUE)){
  install.packages("lmtest")
}

source('calcN.R')
library(car)
library(lmtest)

```

# Sumário
...

# 1. Descrição do Problema

As ferramentas atuais para planejamento de viagens permitem que usuários busquem passagens e hotéis e construam seu próprio itinerário, mas não oferecem suporte para viagens com flexibilidade nas datas ou na ordenação de destinos. Para solucionar esse problema, foi proposto um novo sistema que busca as melhores combinações de passagens e hotéis para uma viagem, minimizando o custo e tempo de transporte. O sistema busca otimizar roteiros com datas flexíveis e não requer uma ordem fixa dos destinos, de forma que considera todas as possíveis configurações que atendem as especificações do usuário. Dessa forma, oferece boas opções de itinerários para viagens com esforço do usuário muito menor, representando uma melhoria significativa na experiência de planejamento de viagens.

O conjunto de restrições do problema considera datas inicial e final, datas específicas para cada destino, ordenação dos destinos e características das acomodações e transportes. Pode ser considerado uma aplicação multiobjetivo do problema do caixeiro viajante com janelas de tempo e dependência temporal.

Para realizar a otimização de roteiros, foi utilizado um algoritmo de colônia de formigas [@cite]. Uma melhoria para o algoritmo utilizando busca local foi proposta. O objetivo do trabalho é comparar os algoritmos e determinar se a melhoria proposta é melhor para solucionar o problema, avaliando tanto o tempo gasto na otimização e a qualidade do conjunto de soluções encontrado. Assim, as perguntas a serem respondidas são:

- TODO
- TODO

No entanto, o tamanho do roteiro a ser avaliado também influencia esses resultados. Assim, é necessário considerar o tamanho da instância como uma covariável do problema. Para lidar com isso, serão utilizadas técnicas de blocagem, e também exploradas técnicas estatísticas de análise de covariância.

```{r,results='show',warning=FALSE,echo=FALSE}
## EXPERIMENTAL DEFINITIONS
v_alpha = 0.05
v_beta = 0.20
v_power = 1-v_beta
v_delta = 0.25
v_dTime = 0.5
v_dQuality = 0.5
```
Os parâmetros experimentais desejados são:

* Nível de significância: $\alpha = `r v_alpha`$;

* Tamanho de efeito de interesse prático: $d^{\star}_time = d^{\star}_quality = `r v_dTime`$;

* Potência desejada: $(1- \beta) = \pi \geq `r v_power`$.


TODO: explicar melhor o problema

# 2. Planejamento Experimental

Os dados experimentais do problema foram obtidos através de simulações. Foram geradas instâncias do problema de diferentes tamanhos. Para cada uma delas, cada algoritmo foi aplicado 8 vezes, e os resultados registrados. A ordem das instâncias geradas e da aplicação dos algoritmos foi aleatorizada de maneira a bloquear possíveis efeitos de ordem.

Nos experimentos, foi medido o tempo gasto na execução de cada algoritmo. Para minimizar a influência de outros processos do sistema, a execução foi limitada a um único núcleo do processador, com prioridade de execução alta.

Cada algoritmo de otimização produz como resultado um conjunto de soluções. A qualidade desse conjunto é medida através do Hipervolume [@cite] do conjunto na fronteira de Pareto, considerando como referência o ponto da solução Nadir na fronteira de Pareto (isto é, a pior solução teórica). Para cada instância avaliada, um novo ponto de referência é calculado através de uma heurística.

O método de Hipervolume é bastante sensível ao ponto de referência definido [@cite]. Sendo assim, a qualidade medida entre diferentes instâncias não tem significado quando comparadas entre si. No entanto, a métrica é eficiente para comparar a qualidade de diferentes conjuntos de solução encontrados no mesmo ponto. Sendo assim, é necessário avaliar a qualidade relativa das soluções em cada instância, e não o seu valor absoluto.

## 2.1 Definição do Tamanho Amostral

O tamanho amostral do problema foi definido a partir de requisitos técnicos do projeto. Era desejável avaliar o efeito dos algortimos para problemas de diferentes tamanhos, partindo do caso mais simples até problemas de tamanho real. No entanto, limitações no tempo de execução do trabalho impediram coleta de dados maiores.

As instâncias geradas utilizaram então combinações de 1 a 4 destinos e 1 a 6 opções de tranportes e acomodação. Para essas características, foi gerado um conjunto de dados com 108 instâncias.

A função power.t.test foi utilizada para calcular o tamanho necessário para os requisitos do projeto, considerando comparações pareadas que podem ser efetuadas após o teste ANOVA. O resultado indica que, para a potência e tamanho de efeito desejados, 108 observações são mais que suficientes.


## 2.2 Análise de Variância com Blocagem

Para a avaliar existência de diferenças significativas entre os dois parâmetros, será utilizado o teste estatístico ANOVA.

Essa técnica analisa médias e variâncias de observações de diferentes grupos para verificar se existe diferença estatístixa significativa entre as médias desses grupos. Assim, generaliza o teste t para mais de dois grupos, permitindo que sejam comparados simultâneamente [@Campelo2015-01], [@MontgomeryRunger2011]. Em outras palavras, a análise de variância é utilizada quando se quer decidir se os níveis apresentam médias diferentes em relação é uma média global $\mu$. As diferenças entre as médias dos níveis e a média global é  $\tau_i$ $\forall \  i$. 

Vale ressaltar que a técnica é restrita apenas à indicação de existência ou não de diferenças entre os níveis avaliados, sem indicar quais níveis seriam diferentes. Além disso, quando a análise de variância tem como resultado um indicativo de refutação da hipótese nula $\eqref{eq:01}$ é que podem ser evidenciados os indícios de diferenças entre os níveis.


\begin{equation}
\left\{\begin{array}{rc}
H_{0}:& \tau_i = 0, \ \ \ \forall i\\
H_{1}:& \exists \ \ \tau_i \neq 0
\end{array}\right.
\label{eq:01}
\end{equation}

Esta etapa foi considerada como uma primeira verificação ao questionamento deste estudo por apresentar uma abordagem que pode minimizar o custo de coleta de amostras menor do que o teste de comparações múltiplas discutido na Seção 2.2. Portanto, caso não seja detectada alguma diferenças entre os níveis, as comparações múltiplas são dispensáveis, o que reduz o custo do experimento.


## 2.3 Análise de Covariância (ANCOVA)

A análise de covariância é uma técnica $-$ assim como a blocagem ou pareamento (em testes-t) $-$ bastante útil para a melhora da precisão de um experimento [@montgomery1984design]. Em diversos aspectos é similar à análise de variância (ANOVA), porém permite ter controle sobre a influência do covariante nas variâveis dependentes. 


A covariável complementa o controle local e, obviamente, necessita estar correlacionada com a variável de resposta para que se possa fazer uso de tal análise. E quando a análise de variância é realizada com uma ou mais covariáveis, é usual chamar a análise de ANCOVA.

Na ANCOVA a variável dependente é contínua (e.g. tempo, velocidade, etc.), enquanto que a variável independente é normalmente categória (e.g. "masculino/feminino", "fumante/não-fumante" etc. ). A análise de variância, por sua vez, poderá converter-se na ANCOVA quando for adicionado um covariante, que consiste em outra variável, que pode ser tanto categórica quanto contínua. 

Existem aliás, duas razões principais para sair-se da ANOVA e passar a ser considerada a análise de covarância, i.e., razões técnicas para adicionar um covariante, quais sejam:

* Reduzir fatores de variabilidade inter-grupos, ou alcançar um nível maior de entendimento a partir da variância desconhecida;

* Isolar o efeito que ocorre quando o controle experimental não permite que o experimentador elimine, de maneira razoável, explicações alternativas para uma relação observada entre variáveis independentes e dependentes, o que é chamado de "confusão" _confounding_. Em outras palavras, esta variável é algo que pode estar influenciando o experimento mas que não está, a principio, no modelo original, e é uma potencial fonte de viéses no experimento.

A ANCOVA, permite, portanto, um controle do erro experimental, aumentando sua precisão. Vale ressaltar que a técnica não é restrita apenas à indicação de existência ou não de diferenças entre os níveis avaliados.

Considerando um experimento com um fator e uma covariável, o modelo estatístico da análise de covariância pode ser estabelecido como [@MontgomeryRunger2011]:
\begin{equation}
y_{ij} = \mu + \tau_{i} + \beta (x_{ij}- \bar{x_{..}}) + \epsilon_{ij} \,,
\label{eq:001}
\end{equation}
em que:
$\mu$ é uma constante, $\tau_{i}$ é o efeito do i-ésimo "tratamento", $X_{ij}$ é o valor observado da covariável e $\bar{x_{..}}$ a média dos valores $x_{ij}$ (da covariável). Além disso, $\beta$ consiste no coeficiente de regressão linear entre a covariável $X$ e a variável de resposta $Y$, com $\beta \neq 0$ e $\epsilon_{ij}$ é uma componente aleatória de erro, com $i = 1, \ldots , a$ e $j = 1, \ldots , n$. Neste caso a relação deve ser linear. Vale ressaltar que este modelo pressupõe que a variável de resposta e a covariável estão relacionadas linearmente. Para efeito de simplificação, contudo, a análise de covariância pode ser vista como uma análise "ajustada" de variância, e pode ser sumarizada na tabela $\eqref{{tab:001}}$:


\begin{table}[]
\centering
\caption{ANCOVA como um ``modelo ajustado'' da ANOVA.}
\label{tab:001}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}|l|c|c|c|c|@{}}
\toprule
\textbf{Fontes de variação} & \textbf{$\sum$ de quadrados}                                                                                        & \textbf{Graus de Lib} & \textbf{média quadrática}    & \textbf{$F_{0}$}                             \\ \midrule
\textbf{regressão}          & $(S_{xy}/S_{xx})$                                                                                                   & $1$                   &                              &                                              \\ \midrule
\textbf{Tratamentos}        & \begin{tabular}[c]{@{}c@{}}$SS'_{E}- SS_{E} - $\\ $(S_{xy})^{2}/S_{xx} - [E_{yy}-(E_{xy})^{2}/E_{xx}]$\end{tabular} & $a-1$                 & $\frac{SS'_{E}-SS_{E}}{a-1}$ & $\frac{1}{MS_{E}}\frac{SS'_{E}-SS_{E}}{a-1}$ \\ \midrule
\textbf{Erro}               & $SS_{E} = E_{yy}-(E_{xy})^{2}/E_{xx}$                                                                               & $a(n-1)-1$            & $\frac{SS_{E}}{a(n-1)-1}$    &                                              \\ \midrule
\textbf{Total}              & S\_\{yy\}                                                                                                           & $an-1$                &                              &                                              \\ \bottomrule
\end{tabular}%
}
\end{table}

em que:
\begin{eqnarray}
S_{yy} &=& \sum \limits_{i=1}^{a} \sum \limits_{j=1}^{n} {y_{ij}^{2}}- \frac{y_{..}^{2}}{an}  \,, \label{eq:002} \\
S_{xx} &=& \sum \limits_{i=1}^{a} \sum \limits_{j=1}^{n}  {x_{i.}^{2}}- \frac{x_{..}^{2}}{an} \,, \label{eq:003} \\
S_{xy} &=& \sum \limits_{i=1}^{a} \sum \limits_{j=1}^{n}  x_{ij}y_{ij} - \frac{(x_{..})(y_{..})}{an} \,, \label{eq:004} \\
T_{yy} &=& \frac{1}{n} \sum \limits_{i=1}^{a} {y_{i.}^{2}}- \frac{y_{..}^{2}}{an} \,, \label{eq:005} \\
T_{xx} &=& \frac{1}{n} \sum \limits_{i=1}^{a}  {x_{i.}^{2}}- \frac{x_{..}^{2}}{an} \,, \label{eq:006} \\
T_{xy} &=& \frac{1}{n}  \sum \limits_{i=1}^{a}  x_{i.}y_{i.} - \frac{(x_{..})(y_{..})}{an}     \,, \label{eq:007} \\
E_{yy} &=& S_{yy}-T_{yy}\,, \label{eq:008} \\
E_{xx} &=& S_{xx} - T_{xx}\,, \label{eq:009} \\
E_{xy} &=& S_{xy} - T_{xy}\,. \label{eq:010}
\end{eqnarray}

Assim, rejeita-se a hipótese nula $H_{0}: \beta=0$ se $F_{0}> F_{\alpha , 1, a(n-1)-1} \,.$


# 3. Resultados Análise Estatística

## 3.1 Tratamento e Validação dos Dados

Após a obtenção dos dados, foi feita uma rotina de validação para identificar possíveis erros. Para isso, as seguintes condições foram avaliadas em cada observação:

1. Tempo $> 0$
2. 0 > Qualidade $> 1$

Em seguida, as diferentes execuções realizadas para cada instância foram agrupadas através da média. Dessa forma, cada bloco considerado é resumido por única estatística.

## 3.2 Análise Exploratória dos Dados

Foi então realizada um análise qualitativa dos dados. Para cada variável de resposta, foram plotados seus gráficos em função do tempo, identificando cada algoritmo.

```{r, echo=FALSE, fig.height=3.8, message=FALSE, warning=FALSE, results='show'}

v_data = readr::read_csv('results_fixed.csv')
v_data$algorithm = as.factor(v_data$algorithm)

v_dataSdRuns = aggregate(cbind(quality,time)~instance:algorithm:size,data=v_data, FUN=sd)

v_data = aggregate(cbind(quality,time,size,avgTransportations,avgAccommodations,destinations)~algorithm:instance, data=v_data, FUN=mean)

v_data$qualityRelative = v_data$quality/array(sapply(subset(v_data, algorithm=='ACO')$quality, function(v) return(rep(v,2))))

par(mfrow=c(1,2), mai=.4*c(2,2,1,0.5))

plot(x = (subset(v_data, algorithm=='ACO')$size),
     y = (subset(v_data, algorithm=='ACO')$time),
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "size",
     ylab = "Time")
points(x = (subset(v_data, algorithm=='ACO_Local')$size),
     y = (subset(v_data, algorithm=='ACO_Local')$time),
     cex  = 1,
     pch  = 18,
     col='blue')
legend("bottomright", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)

plot(x = (subset(v_data, algorithm=='ACO')$size),
     y = subset(v_data, algorithm=='ACO')$qualityRelative,
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "size",
     ylab = "Relative Quality")
points(x = (subset(v_data, algorithm=='ACO_Local')$size),
       y = subset(v_data, algorithm=='ACO_Local')$qualityRelative,
       cex  = 1,
       pch  = 18,
       col='blue')
legend("bottomleft", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)

```

A escala não permite ter uma visualização adequada dos dados. Assim, é aplicada uma transformação logarítmica na variável Size para solucionar esse problema.

```{r, echo=FALSE, fig.height=3.8, message=FALSE, warning=FALSE, results='show'}

par(mfrow=c(1,2), mai=.4*c(2,2,1,0.5))

plot(x = log(subset(v_data, algorithm=='ACO')$size),
     y = (subset(v_data, algorithm=='ACO')$time),
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "Time")
points(x = log(subset(v_data, algorithm=='ACO_Local')$size),
     y = (subset(v_data, algorithm=='ACO_Local')$time),
     cex  = 1,
     pch  = 18,
     col='blue')
legend("topleft", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)

plot(x = log(subset(v_data, algorithm=='ACO')$size),
     y = subset(v_data, algorithm=='ACO')$qualityRelative,
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "Relative Quality")
points(x = log(subset(v_data, algorithm=='ACO_Local')$size),
       y = subset(v_data, algorithm=='ACO_Local')$qualityRelative,
       cex  = 1,
       pch  = 18,
       col='blue')
legend("bottomleft", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)

```


Para normalizar a distribuição dos dados, foi aplicada uma transformação logarítmica também nas variáveis de resposta. Essa transformação também permite obter uma relação mais linear entre a covariável tamanho e o tempo,


```{r, echo=FALSE, fig.height=3.8, message=FALSE, warning=FALSE, results='show'}

par(mfrow=c(1,2), mai=.4*c(2,2,1,0.5))

plot(x = log(subset(v_data, algorithm=='ACO')$size),
     y = log(subset(v_data, algorithm=='ACO')$time),
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "log Time")
points(x = log(subset(v_data, algorithm=='ACO_Local')$size),
     y = log(subset(v_data, algorithm=='ACO_Local')$time),
     cex  = 1,
     pch  = 18,
     col='blue')
legend(x=0, y=4.5, legend=c('ACO', 'ACO+\nLocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)

plot(x = log(subset(v_data, algorithm=='ACO')$size),
     y = log(subset(v_data, algorithm=='ACO')$qualityRelative),
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "Log Relative Quality")
points(x = log(subset(v_data, algorithm=='ACO_Local')$size),
       y = log(subset(v_data, algorithm=='ACO_Local')$qualityRelative),
       cex  = 1,
       pch  = 18,
       col='blue')
legend("bottomleft", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)

```

Os resultados parecem indicar uma relação linear entre tempo e tamanho de problema (ambos em escala logarítmica). Além disso, a qualidade relativa das soluções parece não depender do tamanho. Finalmente, há indícios de que o algoritmo proposto é melhor que a alternativa tanto em quesitos de tempo quanto qualidade da solução encontrada.

## 3.2 Análise de Variância com Blocagem

É então aplicado o método ANOVA com blocagem para obter a significância estatística das variáveis consideradas. Para ser possível aplicar o modelo ANOVA, a variável contínua de tamanho deve ser considerada como um fator. Assim, o tamanho é avaliado como uma variável com 99 níveis (número de tamanhos diferentes nas 108 instâncias avaliadas).
Os testes são realizados para as duas variáveis de resposta.

### Tempo de Execução

Inicialmente, a análise é realizada sem blocagem. Essa análise ignora os efeitos de tamanho do problema e tenta avaliar a diferença de tempo entre os métodos considerando apenas os algoritmos:
```{r, echo=FALSE, fig.height=3.8, fig.width=3.8, message=FALSE, warning=FALSE, results='show'}
summary.aov(aov(log(time)~algorithm, data=v_data))
```

O resultado não indica nenhum efeito significativo dos algoritmos. Isso condiz com o esperado, uma vez que a análise visual indica que quaisquer possíveis efeitos dos algorimos são muito menores que o efeito devido à variações no tamanho.

Incluindo o efeito do tamanho da instância no modelo, tem-se:
```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}
# Time - simple model
v_modelAnovaTime <- aov(log(time)~algorithm+as.factor(log(size)), 
                        data = v_data)
summary.aov(v_modelAnovaTime)
v_r2 = summary.lm(v_modelAnovaTime)$r.square

par(mfrow=c(2,2), mai=.3*c(2.5,1,1,1))
plot(v_modelAnovaTime)

```

Nesse caso, é possível verificar que, uma vez compensado o efeito do tamanho, é possível verificar um efeito do algoritmo utilizado no tempo total de execução. Ainda assim, esse efeito é bastante menor que o efeito do tempo, o que pode concluído observando a relação da soma quadrática dos fatores e dos resíduos. A soma quadrática do tamanho é significativamente maior, o que indica uma maior contribuição desse fator para explicar o efeito observado.

O gráfico de distribuição dos resíduos (e resíduos padronizados) em relação ao valor ajustado indica homocedasticidade. O segundo gráfico quantil-quantil indica que os dados transformados possuem uma distribuição praticamente normal, o que valida a premissa de normalidade. Esses resultados são confirmados pelos testes Fligner-Kileen e Shapiro-Wilk, respectivamente. O design aleatório da ordenação das instâncias nos testes realizados permite assumir independência entre as observações. Assim, as premissas do teste ANOVA são bem atendidas. Finalmente, o gráfico Residuals vs. Leverage não indica nenhum observação com Cook's distance muito diferente dos demais, o que poderia sugerir um possível outlier.

### Qualidade da Solução

A mesma análise realizada para o tempo de execução é aplicada para a qualidade da solução:

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}
v_modelAnovaQuality <- aov(log(qualityRelative)~algorithm+as.factor(log(size)), 
                           data = v_data)
summary.aov(v_modelAnovaQuality)
v_r2 =summary.lm(v_modelAnovaQuality)$r.square

par(mfrow=c(2,2), mai=.3*c(2.5,1,1,1))
plot(v_modelAnovaQuality)

```

O resultado do teste ANOVA condiz com o esperado após a análise exploratória. O algoritmo possui um efeito significativo na qualidade relativa, enquanto o tamanho do problema não possui significância para explicar as diferenças de qualidade entre os algoritmos.

Os gráficos de distribuição dos resíduos e qq-plot possuem uma configuração que desperta dúvidas e pode indicar violações nas premissas. No entanto, essa configuração é consequência da transformação utilizada para avaliar qualidade relativa das soluções, que concentra a qualidade de todas as soluções do algorimo padrão no valor 1.
Para contornar esse problema e avaliar a normalidade da distribuição e homocedasticidade dos resíduos, é então considerada a diferença entre qualidade relativa das soluções

```{r, echo=FALSE, fig.height=3.5, message=FALSE, warning=FALSE, results='show'}
v_dataDiff = aggregate(cbind(quality, time, qualityRelative)~size:instance, data=v_data, FUN=diff)
par(mfrow=c(1,2), mai=.4*c(2,2,1,0.5))
qqPlot(log(v_dataDiff$qualityRelative), main="Normal Q-Q")

plot(x=log(v_dataDiff$qualityRelative), y=v_modelAnovaQuality$residuals[109:216], main="Residuals vs Fitted")
```

O gráfico indica que a distribuição das diferenças é bem próxima da distribuição normal. Não há também indícios de heterocedasticidade, o que valida as premissas do teste.

Uma vez que foi verificado que o tamanho do problema não é significativo para a qualidade relativa da solução, é possível realizar um teste-t pareado para testar a hipótese de que o algoritmo proposto apresenta qualidade maior que o original, considerando um tamanho de efeito de 5%.

```{r, echo=FALSE, fig.height=3.8, fig.width=3.8, message=FALSE, warning=FALSE, results='show'}
v_tTestQuality = t.test((v_dataDiff$qualityRelative),
                        mu = 0,
                        conf.level = 0.95, 
                        alternative = 'greater'
)
v_tTestQuality
```

O p-valor encontrado rejeita a hipótese de que a qualidade dos algoritmos são equivalentes. O intervalo de confiança de 95% obtido indica que a média da diferença relativa de qualidade é de pelo menos 6.137%, em favor do algoritmo proposto.

## 3.3 Análise de Covariância

A Análise de Covariância é uma maneira mais adequada de lidar com variáveis contínuas. Além disso, ela permite realizar a análise mesmo quando uma covariável contínua não pode ser controlada e as observações possuem diferentes valores para a mesma, de forma que não podem ser pareadas.

Para ilustrar esse cenário, o conjunto de dados foi truncado para que, para cada instância, apenas resultados de um algoritmo esteja disponível. O objetivo principal é demonstrar que, mesmo na situação onde não é possível realizar o pareamento, ainda é possível fazer a análise do efeito da variável de interesse. O novo cojunto de dados possui portanto metade das observações do conjunto anterior.

O gráfico abaixo ilustra o novo conjunto de dados, já transformado:

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}
v_data2 = v_data[seq(nrow(v_data)/2)*2 - rep(c(0,1),nrow(v_data)/4),]

par(mfrow=c(1,2), mai=.4*c(2,2,1,0.5))
plot(x = log(subset(v_data2, algorithm=='ACO')$size),
     y = log(subset(v_data2, algorithm=='ACO')$time),
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "log Time")
points(x = log(subset(v_data2, algorithm=='ACO_Local')$size),
       y = log(subset(v_data2, algorithm=='ACO_Local')$time),
       cex  = 1,
       pch  = 18,
       col='blue')
legend(x=1, y=4.5, legend=c('ACO', 'ACO+\nLocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)

plot(x = log(subset(v_data2, algorithm=='ACO')$size),
     y = log(subset(v_data2, algorithm=='ACO')$qualityRelative),
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "log qualityRelative")
points(x = log(subset(v_data2, algorithm=='ACO_Local')$size),
       y = log(subset(v_data2, algorithm=='ACO_Local')$qualityRelative),
       cex  = 1,
       pch  = 18,
       col='blue')
legend("topleft", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)
```

O modelo ANCOVA é primeiro ajustado em relação à uma das variáveis. O erro restante é então ajustado em relação as variáveis seguintes. Sendo assim, há uma relação de dependência da segunda variável em relação à primeira. Por isso, a ordem das variáveis utilizadas no modelo é importante. 

A seguir, é realizada a análise dos dados para cada variável de resposta.

# Tempo

Inicialmente, é ajustado um modelo do tempo tomando o algoritmo como variável independente:

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}
v_modelAncovaTime = aov(log(time)~algorithm+log(size), data=v_data2)
summary.aov(v_modelAncovaTime)
v_r2 = summary.lm(v_modelAncovaTime)$r.square
```

Nesse modelo, não foi identificada nenhuma significância do algoritmo para explicar o tempo de execução, e apenas o tamanho tem significância. Isso condiz com o resultado esperado, uma vez que o efeito do algoritmo observado no gráfico é ordens de grandeza menor que o efeito do tamanho.

Em seguida, ajusta-se um modelo tomando o tamanho como variável independente.

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}

# Time model fit
v_modelAncovaTime2 = aov(log(time)~log(size)+algorithm, data=v_data2)
summary.aov(v_modelAncovaTime2)
v_r2Model2 = summary.lm(v_modelAncovaTime2)$r.square

v_modelFitTime = lm(log(time)~log(size)+algorithm, data=v_data2)

par(mfrow=c(2,2), mai=.3*c(2.5,1,1,1))
plot(v_modelFitTime)
```

Nesse modelo, é possível notar que, uma vez compensado o efeito do tamanho, o algoritmo possui sim um efeito significante no tempo de execução. Assim, a análise realizada leva às mesmas conclusões que o teste ANOVA aplicado na seção anterior.

Os gráficos e testes realizados permitem avaliar a normalidade dos dados e homocedasticidade dos resíduos. Há indícios de pequenas violações na normalidade, mas o método ANCOVA é robusto a isso.

Abaixo, é feita uma regressão linear dos resultados, que parece indicar que o algoritmo original possui tempos um pouco menores que o proposto.

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}

plot(x = log(subset(v_data2, algorithm=='ACO')$size),
     y = log(subset(v_data2, algorithm=='ACO')$time),
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "log Time")
points(x = log(subset(v_data2, algorithm=='ACO_Local')$size),
       y = log(subset(v_data2, algorithm=='ACO_Local')$time),
       cex  = 1,
       pch  = 18,
       col='blue')
legend("topleft", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)
abline(coef=c(v_modelFitTime$coefficients[1],v_modelFitTime$coefficients[2]), col='red')
abline(coef=c(v_modelFitTime$coefficients[1]+v_modelFitTime$coefficients[3],v_modelFitTime$coefficients[2]), col='blue')
```

# Qualidade

A mesma análise é feita para a qualidade dos algoritmos:

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}
v_modelAncovaQual = aov(log(qualityRelative)~algorithm+log(size), data=v_data2)
summary.aov(v_modelAncovaQual)
v_r2 = summary.lm(v_modelAncovaQual)$r.square

#v_modelAncovaQual2 = aov(log(qualityRelative)~log(size)+algorithm, data=v_data2)
#summary.aov(v_modelAncovaQual2)
#v_r2Model2 = summary.lm(v_modelAncovaQual2)$r.square

v_modelFitQuality = lm(log(qualityRelative)~log(size)+algorithm, data=v_data2)

par(mfrow=c(2,2), mai=.3*c(2.5,1,1,1))
plot(v_modelFitQuality)
```

O resultado novamente condiz com o resultado obtido no teste ANOVA. O algoritmo tem um efeito significativo sobre a qualidade relativa, enquanto o tamanho do problema não. As premissas de normalidade e homocedasticidade são validadas de maneira análoga ao teste ANOVA.

A regressão linear abaixo permite observar a superioridade da média da qualidade relativa do algoritmo proposto, bem como o efeito (praticamente nulo) do tamanho do problema.

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}
plot(x = log(subset(v_data2, algorithm=='ACO')$size),
     y = log(subset(v_data2, algorithm=='ACO')$qualityRelative),
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "Log qualityRelative")
points(x = log(subset(v_data2, algorithm=='ACO_Local')$size),
       y = (log(subset(v_data2, algorithm=='ACO_Local')$qualityRelative)),
       cex  = 1,
       pch  = 18,
       col='blue')
legend("bottomright", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)
abline(coef=c(v_modelFitQuality$coefficients[1],v_modelFitQuality$coefficients[2]), col='red')
abline(coef=c(v_modelFitQuality$coefficients[1]+v_modelFitQuality$coefficients[3],v_modelFitQuality$coefficients[2]), col='blue')

```


# Validação das Premissas

Conforme discutido na seção 2.3, o teste ANCOVA depende fortemente da premissa de igualdade do coeficiente das retas de regressão de cada grupo avaliado em relação à covariável. Para verificar se essa premissa é atendida, é considerado um modelo com termos de interação entre tempo e tamanho do problema.

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}
# Time - iteraction effects
v_modelAncovaTime2 <- aov(log(time)~algorithm*log(size), 
                        data = v_data)
summary.aov(v_modelAncovaTime2)
v_r2 = summary.lm(v_modelAncovaTime2)$r.square

par(mfrow=c(2,2), mai=.3*c(2.5,1,1,1))
plot(v_modelAncovaTime2)
```

O resultado desse modelo indica que o termo de iteração é significante para explicar o tempo de execução. Isso é um sinal de que a premissa pode ser violada. Realizando a regressão com um modelo com termos de iteração, o seguinte resultado é obtido:

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='show'}

v_modelFitTime = lm(log(time)~log(size)*algorithm, data=v_data2)

plot(x = log(subset(v_data2, algorithm=='ACO')$size),
     y = log(subset(v_data2, algorithm=='ACO')$time),
     cex  = 1,
     las  = 1,
     pch  = 16,
     col='red',
     xlab = "log size",
     ylab = "Time")
points(x = log(subset(v_data2, algorithm=='ACO_Local')$size),
       y = log(subset(v_data2, algorithm=='ACO_Local')$time),
       cex  = 1,
       pch  = 18,
       col='blue')
legend("topleft", legend=c('ACO', 'ACO+LocalSearch'), col=c("red", "blue"),  pch=c(16,18), cex=1)

abline(coef=c(v_modelFitTime$coefficients[1],v_modelFitTime$coefficients[2]), col='red')
abline(coef=c(v_modelFitTime$coefficients[1]+v_modelFitTime$coefficients[3],v_modelFitTime$coefficients[2]+v_modelFitTime$coefficients[4]), col='blue')
```

Analisando o gráfico e os coeficientes de regressão linear obtidos, é possível verificar que a premissa não é atendida. O resultado sugere que o efeito do algoritmo no tempo depende do tamanho de problema. Na regressão realizada, o algoritmo original tem um efeito positivo sobre o tempo para problemas menores, em relação ao algoritmo proposto. No entanto, após um determinado tamanho, essa relação se inverte.

Esse resultado sugere que, para problemas maiores, o efeito do algoritmo original no tempo passa a ser pior em relação ao algoritmo proposto. No entanto, seria necessário outro experimento para investigar esse efeito.


# 4. Discussão e Conclusões

Os resultados encontrados refutam a hipótese de equivalência dos algorimos em relação à qualidade relativa entre eles. O intervalo de confiança de 95% observado indica vantagem superior a 6% no algoritmo proposto em relação ao original.

Além disso, é possível observar que o tamanho do problema não afeta a qualidade relativa entre os algoritmos, dentro do universo considerado. Esse resultado sugere que ambos os algoritmos são afetados da mesma forma por variações no tamanho da instância considerada.

Em relação ao tempo até convergência dos algoritmos, foi verificado que o tamanho do problema é o principal fator que influencia esse resultado. Compensada a influência do tamanho, um pequeno efeito dos algoritmos foi verificado, favorecendo o algoritmo original. No entanto, apesar de estatísticamente significante, esse efeito não tem um tamanho de efeito suficiente para ter relevância prática.

Além disso, a análise realizada sugere um efeito de iteração entre algoritmo e tamanho do problema sobre o tempo de convergência. A regressão utilizada apresenta indícios de que, para problemas menores, o algoritmo original apresenta menores tempos. No entanto, para problemas maiores, o algoritmo proposto parece ter resultados melhores também no tempo. No entanto, é necessário um segundo experimento para confirmar essas observações, incluindo instância maiores.

A interpretação desses resultados pode ser complementada por conhecimentos do problema. O algoritmo proposto é uma modificação do original que acrescenta uma busca local ao final de cada iteração. Para problemas pequenos, é bastante fácil encontrar as soluções ótimas do problema. Parece que a modificação proposta acrescenta um custo adicional de processamento, o que afeta o tempo para convergência.

A medida que os problemas crescem, a rotina de busca local parece permitir que resultados melhores sejam encontrados antes que o método convirja, mas ainda com um tempo um pouco maior. Para problemas ainda maiores e mais complexos, a convergência é mais lenta para ambos os métodos. No entanto, a melhoria da qualidade decorrente da busca local parece ter vantagem aqui, acelerando a convergência e garantindo soluções melhores.

Além disso, vale a pena observar que os problemas de maior interesse prático e aplicabilidade apresentam tamanhos maiores. Sendo assim, é mais interessante escolher um método que apresente vantagens nesses casos. Após o estudo, recomenda-se a aplicação do método proposto devido aos ganhos de qualidade sem diferença significativa no tempo. No entanto, também é sugerido um segundo experimento para observar o comportamento dos algoritmos em problemas maiores.

Finalmente, o trabalho permitiu também explorar a técnica ANCOVA. Ela é muito adequada para problemas com covariáveis contínuas, e é especialmente necessária quando essas variáveis não são controláveis e apresentam diferentes níveis. No entanto, é necessário atenção para as premissas dos teste, em especial a premissa de igualdade dos coeficientes de regressão. A violação dessa premissa eleva as taxas de erro e pode levar a conclusões erradas.

# Referências