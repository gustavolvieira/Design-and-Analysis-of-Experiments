---
title: 'Estudo de Caso 03: Comparison of Rising Drilling Configurations'
author: "Equipe 04"
date: "24 de Junho de 2017"
output:
  pdf_document:
    fig_caption: yes
  word_document: default
header-includes:
- \usepackage{fancyhdr}
- \usepackage[utf8]{inputenc}
- \pagestyle{fancy}
- \fancyfoot[CO,CE]{EEE933 - Planejamento e Análise de Experimentos}
- \fancyfoot[LE,RO]{\thepage}
csl: ieee.csl
bibliography: bibliography.bib
---  
Coordenador: Bernardo Marques   
Relator: Danny Tonidandel   
Verificador: Gustavo Vieira   
Monitor: Alessandro Cardoso

```{r setup,include=FALSE, results='hide',warning=FALSE,echo=FALSE}
if (!require(readr, quietly = TRUE)){
  install.packages("readr")
}
if (!require(car, quietly = TRUE)){
  install.packages("car")
}
if (!require(lmtest, quietly = TRUE)){
  install.packages("lmtest")
}
source('calcN.R')
library(car)
library(lmtest)

```

# 1. Descrição do Problema
O objetivo do problema é realizar uma comparação entre quatro tipos de tubos de perfuração _drilling risers_, que consiste em uma espécie de conduíte ou tubo utilizado para servir como passagem temporária para o petróleo extraído em plataformas oceânicas. Mais especificamente, pretende-se comparar o tempo médio até a falha _(mean time to failure ou MTTF)_ de quatro configurações diferentes (níveis $A$, $B$, $C$, $D$) de equipamentos, de forma a escolher a que forneça a menor probabilidade de falha, considerando-se um período de $20$ anos. Para isto serão comparadas a configuração padrão _(Riser 1)_ com as outras três, buscando encontrar qual delas proverá o maior _MTTF_. Ou seja, a questão a se responder é:

Algum dos risers alternativos é melhor que o padrão?

A plataforma de testes escolhida pela equipe de engenharia consiste na utilização de um modelo em escala para os _risers_ com um protocolo de tempo acelerado, em que há uma relação direta entre o tempo medido de cada observação (em minutos) e a configuração do sistema real. Todavia, o custo de cada observação é significativamente custoso, sendo cerca de $US\$10.000$ (dez mil dólares). Afim de minimizar os custos com amostras coletadas é possível utilizar os dados históricos existentes para a primeira configuração _(Riser1)_.

```{r,results='show',warning=FALSE,echo=FALSE}
## EXPERIMENTAL DEFINITIONS
v_alpha = 0.05
v_a = 4
v_k = v_a-1
v_alphaAdj = v_alpha/v_k
v_beta = 0.15
v_power = 1-v_beta
v_delta = 0.25
```
Os  parâmetros experimentais desejados são:

* Nível de significância: $\alpha = 0.05$;

* Tamanho de efeito de interesse prático: ${d^{\star}_{t}} = 0.25$;

* Potência desejada: $(1- \beta) = \pi  \geq 0.85$.

# 2. Planejamento Experimental

Esta etapa do presente estudo de caso consiste em investigar o comportamento dos níveis de fator a partir de uma análise exploratória, e posteriormente, aplicar um teste de comparações múltiplas para as médias. A variância do processo é desconhecida e será estimada utilizando-se os dados históricos de operação fornecidos em <https://git.io/vHDG3. A variância será considerada como sendo uniforme para todas as configurações neste estudo.

Os dados experimentais utilizados foram obtidos através de simulação, por meio de um [aplicativo web] <http://orcslab.cpdee.ufmg.br:3838/riserdata/. A data de nascimento do segundo membro mais jovem da equipe (15/10/1992) foi o parâmetro utilizado como semente para o gerador de números da simulação. Os dados gerados informam uma tabela com os níveis de cada fator de interesse em uma coluna e os tempos (tomados em escala logarítmica) em coluna respectiva.

Os dados estão na escala de _log_ e serão analisados nesta escala, pois não necessitam de tranformação para tal.

## 2.1 Análise de Variância
 
Para a avaliar o questionamento acima, será utilizada a ferramenta estatística para análise de variância denominada ANOVA.

A técnica ANOVA compara médias de diferentes amostras para verificar se estas possuem médias iguais ou não. Assim, essa técnica permite que vários grupos sejam comparados [@Campelo2015-01], [@MontgomeryRunger2011].

Em outras palavras, a análise de variância é utilizada quando se quer decidir se os níveis apresentam médias diferentes em relação é uma média global $\mu$. As diferenças entre as médias dos níveis e a média global é $\tau_i$ $\forall \  i$ . Desta forma a ANOVA se basea no teste de a hipóteses abaixo, onde quando refutado a hipótese nula, evidencia-se indícios de diferenças entre os níveis.

Esta técnica é restrita apenas à indicação da existência ou não de diferenças entre os níveis avaliados sem indicar quais níveis seriam diferentes.




$$
\left\{\begin{array}{rc}
H_{0}:& \tau_i = 0, \ \ \ \forall i\\
H_{1}:& \exists \ \ \tau_i \neq 0
\end{array}\right.
$$
Esta etapa foi considerada como uma primeira verificação ao questionamento deste estudo por apresentar um custo de coleta de amostras menor do que o teste de comparações múltiplas discutido abaixo. Portanto, caso não seja detectada alguma diferenças entre os níveis o estudo será concluído por meio do teste ANOVA.

## 2.2 Comparações Múltiplas

Caso a análise ANOVA identifique a existência de diferenças entre os níveis, deve-se proceder com testes de comparação múltiplas todos contra um, no intuito de identificar qual ou quais níveis apresentam tal diferença.

Desta forma, somente, caso a análise de variância indique a existência de diferenças entre os níveis, será aplicado o teste de comparações múltiplas um-contra-todos (_one-vs-all_) de _Dunnett_, onde os _Risers_ propostos serão confrontados com a configuração padrão _Riser1_ para verificar se alguma proposta traria ganho de _MTTF_ frente à configuração já estabelecida.

Para que se proceda com o teste de comparações múltiplas, deve-se manter o controle sobre os erros do tipo-$I$ em cada comparação. É preciso corrigir os valores de $\alpha$ para cada teste. A escolha para este caso é o método de correção de Bonferroni:
$$\alpha_{adj} = \frac{\alpha_{família}}{K} \,,$$ 

no qual $K=3$ é o número de comparações a serem feitas que no caso do teste um-contra-todos de _Dunnett_ é confome abaixo:

$$K=a-1 \,,$$
onde $a$ é o número de níveis, que neste do estudo é 4 e o $\alpha$ experimental desejado é o  $\alpha_{família} = 0.05$. Assim o valor de $\alpha_{adj} = 0.0167$


## 2.3 Definição do Tamanho Amostral
Para calcular o tamanho amostral, utilizaremos as mesmas relações utilizadas na comparação de duas amostras independentes emparelhadas "todos contra um", alterando-se apenas os valores de $\alpha$ para os valores corrigidos $\alpha_{adj}$ para as múltiplas hipóteses e $a-1$ comparações. O tamanho amostral para o teste unilateral para os risers que serão comparados com o já estabelecido é calculado como abaixo:
$$n_i = \left(1 + \frac{1}{K}\right) \left( \frac{\hat{\sigma}}{\delta^{\star}}\right)^{2}(t_{\alpha_{adj}}+t_{\beta})^{2} \,, $$
em que $t_{\alpha_{adj}}$ e $t_{\beta}$ são dependentes de $n$. Para solucionar esse problema, eles foram substituídos por $z_{\alpha_{adj}}$ e $z_{\beta}$ e a equação foi testada iterativamente até a convergência (implementação em anexo no arquivo  _calcN.R_). Dessa forma, foi encontrado o valor $n_i = 58$.

Contudo, para maximizar o poder do procedimento de múltiplas comparações, o tamanho amostral do grupo de controle deve ser calculado como [@Campelo2015-01]:

$$n_0 = n_i\sqrt{K} \,,$$

Lembrando que $K$ é o número de comparações (3), temos que $n_i = 101$


```{r,results='show',warning=FALSE,echo=FALSE}
## SAMPLE SIZE CALC
v_dataHist = readr::read_csv('riser1.csv')
v_sdHist = sd(v_dataHist$LogTTF)

v_n = calcN_oneVsAll(p_alpha = v_alphaAdj,
            p_beta = v_beta,
            p_alternative = 'one-sided',
            p_k = v_k,
            p_sd = v_sdHist,
            p_delta = v_delta
)

v_nControl = ceiling(v_n*sqrt(v_k))

v_tau = c(-v_delta*(v_a-1)/v_a, rep(v_delta/v_a, v_k))
vartau = var(v_tau)
v_nAnova = power.anova.test(groups = v_a, 
                            between.var = vartau, 
                            within.var = v_sdHist^2, 
                            sig.level = v_alpha, 
                            power = v_power)$n

v_nControl = ceiling(v_n*sqrt(v_k))

v_tau = c(-v_delta*(v_a-1)/v_a, rep(v_delta/v_a, v_k))
#v_tau = c(-v_delta/2, v_delta/2, rep(0, v_k-1))
vartau = var(v_tau)
v_nAnova = power.anova.test(groups = v_a, 
                            between.var = vartau, 
                            within.var = v_sdHist^2, 
                            sig.level = v_alpha, 
                            power = v_power)$n

```


Foi também feito o cálculo do tamanho amostral para a técnica  ANOVA. Isto é feito fazendo-se sucessivas iterações em $n$ até que:
$$F_{(1-\alpha)}=F_{\beta;\phi}$$
onde ambas distribuições $F$ tem $(a-1)$ graus de liberdade no numerador e $a(n-1)$ no denomiador. O parâmetro de não-centralidade $\phi$ é dada por:
$$\phi=(n\sum_{i=1}^{a}\tau^2_i)/\hat\sigma^2 $$
e o valor de $\tau$ no caso de comparações todos contra um é dado por:
$$\tau = \left( -\frac{(a-1)\delta^{\star}}{a}, \frac{\delta^{\star}}{a}, \frac{\delta^{\star}}{a}, \frac{\delta^{\star}}{a} \right) $$
e o valor encontrado para o tamanho amostral do ANOVa é $n=60$


Desta forma, tem-se a seguinte situação:

Número de amostras necessárias para o ANOVA: $60*3+50=230$

Número de amostras necessárias a compração todos contra um: $58*3 + 91 =265$

Desta forma, o preço para o ANOVA é de $\$2.300.000$ e o preço das comparações é $\$2.650.000$. O ANOVA precisa de 60 amostras por grupo e as comparações de 58 (fora o grupo controle), o que resultaria em uma sobreamostragem de 2 unidades por grupo. Porém, caso o ANOVA não dê resultado de diferença entre os risers, seriam economizados $\$350.000$ fazendo o ANOVA antes. Essa informações estão apresentadas na tabela 1.

\begin{table}[]
\centering

\begin{tabular}{|l|l|l|}
\hline
          & Melhor caso & Pior caso   \\ \hline
Com ANOVA & \$2.300.000 & \$2.710.000 \\ \hline
Sem ANOVA & \$2.650.000 & \$2.650.000 \\ \hline
Diferença & \$350.000   & -\$60,000   \\ \hline
\end{tabular}
\caption{Análise de preço das opções}
\label{my-label}
\end{table}

Será seguido o caminho com o ANOVA por causa da grande possível economia e da não tão significante gasto com a sobre amostragem caso o ANOVA identifique diferença entre os risers.

## 2.4 Tratamento e Validação dos Dados

Considerando o experimento realizado, foi criada uma rotina para validação dos dados obtidos e identificação de erros, onde o tempo de _MTTF_ na escala logarítma deve ser maior que $0$. 

1. LogTTF $> 0$

Caso os valores de uma execução não atendam essas condições, ela seria descartada. No entanto, nenhuma das amostras apresenta problema.


# 3. Análise Estatística

## 3.1 Análise de Variância

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=4, fig.width=6}
v_data = readr::read_csv('1992-10-15_60_60_60_60.csv')
v_data$Riser = as.factor(v_data$Riser)
boxplot(LogTTF~Riser, 
        data = v_data, 
        xlab = "Riser",
        ylab = "LogTTF", 
        main = "Riser data",
        pch  = 16,
        col  = "gray")
v_model <- aov(LogTTF~Riser, 
             data = v_data)
summary.aov(v_model)
```

Como pode ser observado, o gráfico acima não indica visualmente diferença significativa entre os níveis. Corrobora com isto, o _F-valor = 0.608_ do teste ANOVA indicando pela não rejeição da hipótese de que não há diferença entre os grupos.

Este resultado também indica que não há necessidade de testes de comparação múltiplas que verificariam quais níveis teriam se apresentado diferentes do grupo de controle _Riser1_.

## 3.2 Validação das Premissas

### Normalidade

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=5}
shapiro.test(v_model$residuals)

qqPlot(v_model$residuals, 
       pch = 16, 
       lwd = 3, 
       cex = 2, 
       las = 1)
```

O _p-valor = 0.299_ encontrado no teste de _Shapiro-Wilk_ indica pela rejeição normalidade das amostras
No entanto, qq plot mostra que as violações de normalidade são relativamente pequenas. A análise ANOVA é robusto a pequenas variações de normalidade [@Campelo2015-01]. Desta forma considerou-se a premissa de normalidade atendida.

### Homocedasticidade

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=3.5}
fligner.test(LogTTF~Riser, 
             data = v_data)

plot(x    = v_model$fitted.values,
     y    = v_model$residuals,
     cex  = 2,
     las  = 1,
     pch  = 16,
     xlab = "Fitted values",
     ylab = "Residuals")
grid(NULL,NULL, lwd=2, col = "#44444422")
```

O teste de igualdade de variância dos resíduos de _Fligner-Killeen_ apresentou um _p-valor = 0.1416_ o que também indica pela rejeição da homocedasticidade das amostras.

Contudo, podemos observar no gráfico acima, uma variância relativamente baixa entre os resíduos das amostras. Novamente com base de que a análise ANOVA é robusto a pequenas variações também de homocedasticidade como indicado por [@Campelo2015-01], considerou-se a premissa atendida.


### Independência

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=3.5}
v_dwTest = durbinWatsonTest(v_model)
v_dwTestp = v_dwTest$p

plot(x    = seq_along(v_model$residuals),
     y    = v_model$residuals,
     type = "l",
     las  = 1,
     lwd  = 2,
     lty  = 1,
     xlab = "Residual order",
     ylab = "Residual value")
#points(x    = seq_along(v_model$residuals),
#       y    = v_model$residuals,
#       type = "p",
#       cex  = 2,
#       pch  = 5,
#       col  = as.numeric(v_data[, 2]))
grid(NA,NULL, lwd=2, col = "#44444422")
```

O plot dos valores ordenados de diferenças de tempo entre os algoritmos não apresenta nenhum indício de dependência temporal dos valores. O teste de autocorrelação serial Durbin-Wastson apresenta $p = `r v_dwTestp`$, o que reforça a hipótese de que não há autocorrelação serial entre as amostras.


# 4. Discussão e Conclusões

Os testes realizados levam às seguintes conclusões:

Variância entre grupos é explicada pela variância intra grupo. Não há indício de diferença significativa entre eles.

Recomenda-se manter riser 1. Custo do experimento é significativo $(\$2.300.000)$, mas previniu um custo potencialmente maior de trocar o Riser.

# Referências