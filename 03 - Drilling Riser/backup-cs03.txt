---
title: 'Estudo de Caso 03: Comparison of Rising Drilling Configurations'
author: "Equipe 04"
date: "24 de Junho de 2017"
output:
  pdf_document:
    fig_caption: yes
  word_document: default
header-includes:
- \usepackage{fancyhdr}
- \usepackage[utf8]{inputenc}
- \pagestyle{fancy}
- \fancyfoot[CO,CE]{EEE933 - Planejamento e Análise de Experimentos}
- \fancyfoot[LE,RO]{\thepage}
csl: ieee.csl
bibliography: bibliography.bib
---  
Coordenador: Bernardo Marques   
Relator: Danny Tonidandel   
Verificador: Gustavo Vieira   
Monitor: Alessandro Cardoso

```{r setup,include=FALSE, results='hide',warning=FALSE,echo=FALSE}
if (!require(readr, quietly = TRUE)){
  install.packages("readr")
}
if (!require(car, quietly = TRUE)){
  install.packages("car")
}
if (!require(lmtest, quietly = TRUE)){
  install.packages("lmtest")
}
source('calcN.R')
library(car)
library(lmtest)

```

# 1. Descrição do Problema
O objetivo do problema é realizar uma comparação entre quatro tipos de tubos de perfuração _drilling risers_, que consiste em uma espécie de conduíte ou tubo utilizado para servir como passagem temporária para o petróleo extraído em plataformas oceânicas. Mais especificamente, pretende-se investigar o tempo médio até a falha ( _mean time to failure ou MTTF_ ) de quatro configurações diferentes (níveis $A$, $B$,$C$,$D$) de equipamentos, de forma a escolher a que forneça a menor probabilidade de falha, considerando-se um período de $20$ anos, isto é, comparar a configuração padrão _(Riser 1)_ com as outras três, buscando encontrar qual delas proverá o maior _MTTF_.

A plataforma de testes escolhhida pela equipe de engenharia consiste na utilização de um modelo em escala para os _rirers_ com um protocolo de tempo acelerado, em que há uma relação direta entre (cada observação do) o tempo medido (em minutos) e a configuração do sistema real. Todavia, o custo de cada observação é altíssimo, cerca de  $US\$10000 $  (dez mil dólares). Uma alternativa consiste em utilizar dados históricos existentes para a primeira configuração _(Riser1)_, que não impactará em custos adicionais para o experimento. 
```{r,results='show',warning=FALSE,echo=FALSE}
## EXPERIMENTAL DEFINITIONS
v_alpha = 0.05
v_a = 4
v_k = v_a-1
v_alphaAdj = v_alpha/v_k
v_beta = 0.15
v_power = 1-v_beta
v_delta = 0.25
```
O  parâmetros experimentais de interesse são:

* Nível de significância: $\alpha = 0.05$;

* Tamanho de efeito de interesse prático: ${d^{\star}_{t}} = 0.25$;

* Potência desejada: $(1- \beta) = \pi  \geq 0.85$.

# 2. Planejamento Experimental

Esta etapa do presente estudo de caso consiste em investigar o comportamento dos níveis de fator a partir de uma análise exploratória, e posteriormente, aplicar um teste de comparações múltiplas para as médias. A variância do processo é desconhecida, no entanto será considerada como sendo uniforme para todas as configurações.

Os dados experimentais utilizados foram obtidos através de simulação, por meio de um [aplicativo web] <http://orcslab.cpdee.ufmg.br:3838/riserdata/. A data de nascimento do segundo membro mais jovem da equipe (15/10/1992) foi o parâmetro utilizado como semente para o gerador de números da simulação. Os dados gerados informam uma tabela com os níveis de cada fator de interesse em uma coluna e os tempos (tomados em escala logarítmica) em coluna respectiva. 

## 2.1 Análise de Variância

Discutir ANOVA


## 2.2 Comparações Múltiplas

Discutir análise one-vs-all necessária depois do anova, se diferença for verificada.

Comentar alpha ajustado

Sempre que possível, deve-se trabalhar com o menor número possível de comparações e, no presente caso, em virtude do alto custo. Como a intenção é comparar $-$ caso a diferença entre as configurações seja detectada $-$ em um primeiro momento, os valores médios do grupo 1 em relação aos outros, mantendo-se certo controle sobre os erros do tipo-$I$ em cada teste, é preciso corrigir os valores de $\alpha$ para cada teste. A escolha para este caso é o méttodo de correção de Bonferroni:
$$\alpha_{adj} = \frac{\alpha_{família}}{K} \,,$$ no qual $K=3$ representa o número de comparações ($K = a-1$, em que $a$ é o número de níveis) e $\alpha_{family} = 0.05$.

## 2.3 Definição do Tamanho Amostral
Para calcular o tamanho amostral neste caso, utilizaremos, portanto, as mesmas relações utilizadas na comparação de duas amostras independentes emparelhadas "todos contra um", alterando-se apenas os valores de $\alpha$ para os valores corrigidos $\alpha_{adj}$ para as múltiplas hipóteses e $a-1$ comparações:
$$n_i = \left(1 + \frac{1}{K}\right) \left( \frac{\hat{\sigma}}{\delta^{\star}}\right)^{2}(t_{\alpha_{adj}}+t_{\beta})^{2} \,, $$
com $n_0 = n_i\sqrt{K} \,,$

em que $t_{\alpha_{adj}}$ e $t_{\beta}$ são dependentes de $n$. Para solucionar esse problema, eles foram substituídos por $z_{\alpha_{adj}}$ e $z_{\beta}$ e a equação foi testada iterativamente até convergência (implementação em anexo no arquivo  _calcN.R_). Dessa forma, foi encontrado o valor $n_1 = 60$.

```{r,results='show',warning=FALSE,echo=FALSE}
## SAMPLE SIZE CALC
v_dataHist = readr::read_csv('riser1.csv')
v_sdHist = sd(v_dataHist$LogTTF)

v_n = calcN_oneVsAll(p_alpha = v_alphaAdj,
            p_beta = v_beta,
            p_alternative = 'one-sided',
            p_k = v_k,
            p_sd = v_sdHist,
            p_delta = v_delta
)

v_nControl = ceiling(v_n*sqrt(v_k))

v_tau = c(-v_delta*(v_a-1)/v_a, rep(v_delta/v_a, v_k))
vartau = var(v_tau)
v_nAnova = power.anova.test(groups = v_a, 
                            between.var = vartau, 
                            within.var = v_sdHist^2, 
                            sig.level = v_alpha, 
                            power = v_power)$n

v_nControl = ceiling(v_n*sqrt(v_k))

v_tau = c(-v_delta*(v_a-1)/v_a, rep(v_delta/v_a, v_k))
#v_tau = c(-v_delta/2, v_delta/2, rep(0, v_k-1))
vartau = var(v_tau)
v_nAnova = power.anova.test(groups = v_a, 
                            between.var = vartau, 
                            within.var = v_sdHist^2, 
                            sig.level = v_alpha, 
                            power = v_power)$n

```


Já temos então, neste ponto, subsídios para o cálculo do tamanho amostral do ANOVA: 
(Discutir essa ideia ainda... bla bla)

$$\tau = \left( -\frac{(a-1)\delta^{\star}}{a}, \frac{\delta^{\star}}{a}, \frac{\delta^{\star}}{a}, \frac{\delta^{\star}}{a} \right) $$

Número necessário pra anova: 60*3 + 50

Número necessário pra análises subsequentes: 58*3 + (101 - 10)

Mais barato fazer ANOVA antes e pegar mais amostras do grupo 1 apenas se necessário.
N das comparações multiplas não é tão grande por ser unilateral.

CUSTO TOTAL!

## 2.4 Tratamento e Validação dos Dados

Considerando o experimento realizado, foi criada uma rotina para validação dos dados obtidos e identificação de erros. bla bla

1. LogTTF $> 0$

Caso os valores de uma execução não atendam essas condições, ela seria descartada. No entanto, nenhuma das amostras apresenta problema.


# 3. Análise Estatística

## 3.1 Análise de Variância

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=4, fig.width=6}
v_data = readr::read_csv('1992-10-15_60_60_60_60.csv')
v_data$Riser = as.factor(v_data$Riser)
boxplot(LogTTF~Riser, 
        data = v_data, 
        xlab = "Riser",
        ylab = "LogTTF", 
        main = "Riser data",
        pch  = 16,
        col  = "gray")
v_model <- aov(LogTTF~Riser, 
             data = v_data)
summary.aov(v_model)
```

Gráfico não indica visualmente diferença significativa. 
P valor grande -> não rejeita hipótese de que não há diferença

Não é necessário fazer comparação múltipla.

## 3.2 Validação das Premissas

### Normalidade

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=5}
shapiro.test(v_model$residuals)

qqPlot(v_model$residuals, 
       pch = 16, 
       lwd = 3, 
       cex = 2, 
       las = 1)
```

p valor rejeita normalidade
No entanto, qq plot mostra que as violações de normalidade são muito pequenas. Anova é robusto a pequenas variações, então tudo ok. =)

### Homocedasticidade

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=3.5}
fligner.test(LogTTF~Riser, 
             data = v_data)

plot(x    = v_model$fitted.values,
     y    = v_model$residuals,
     cex  = 2,
     las  = 1,
     pch  = 16,
     xlab = "Fitted values",
     ylab = "Residuals")
grid(NULL,NULL, lwd=2, col = "#44444422")
```

Comentar plot e p valor. Variância praticamente a mesma 


### Independência

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=3.5}
v_dwTest = durbinWatsonTest(v_model)
v_dwTestp = v_dwTest$p

plot(x    = seq_along(v_model$residuals),
     y    = v_model$residuals,
     type = "l",
     las  = 1,
     lwd  = 2,
     lty  = 1,
     xlab = "Residual order",
     ylab = "Residual value")
#points(x    = seq_along(v_model$residuals),
#       y    = v_model$residuals,
#       type = "p",
#       cex  = 2,
#       pch  = 5,
#       col  = as.numeric(v_data[, 2]))
grid(NA,NULL, lwd=2, col = "#44444422")
```

O plot dos valores ordenados de diferenças de tempo entre os algoritmos não apresenta nenhum indício de dependência temporal dos valores. O teste de autocorrelação serial Durbin-Wastson apresenta $p = `r v_dwTestp`$, o que reforça a hipótese de que não há autocorrelação serial entre as amostras.


# 4. Discussão e Conclusões

Os testes realizados levam às seguintes conclusões:

Variância entre grupos é explicada pela variância intra grupo. Não há indício de diferença significativa entre eles.

Recomenda-se manter riser 1. Custo do experimento é significativo, mas previniu um custo potencialmente maior de trocar o Riser.

# Referências
