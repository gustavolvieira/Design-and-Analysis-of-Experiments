---
title: 'Estudo de Caso 02: Comparação entre Algoritmos de Classificação'
author: "Equipe 04"
date: "15 de Maio de 2017"
output:
  pdf_document:
    fig_caption: yes
  word_document: default
header-includes:
- \usepackage{fancyhdr}
- \usepackage[utf8]{inputenc}
- \pagestyle{fancy}
- \fancyfoot[CO,CE]{EEE933 - Planejamento e Análise de Experimentos}
- \fancyfoot[LE,RO]{\thepage}
csl: ieee.csl
bibliography: bibliography.bib
---  
Coordenador: Danny Tonidandel   
Relator: Alessandro Cardoso   
Verificador: Gustavo Vieira   
Monitor: Bernardo Marques   

```{r setup,include=FALSE, results='hide',warning=FALSE,echo=FALSE}
  if (!require(readr, quietly = TRUE)){
    install.packages("readr")
  }
  if (!require(car, quietly = TRUE)){
    install.packages("car")
  }
  if (!require(lmtest, quietly = TRUE)){
    install.packages("lmtest")
  }
  source('calcN.R')
library(car)
library(lmtest)


# pilot size calc
v_nPilot = calcN_pilotD(p_alpha = 0.05,
                        p_beta = 0.2,
                        p_type = 'one-sided',
                        p_d = 1
                        )


# sample size calc
v_data = readr::read_csv('pilot_1992-11-21_17_30.csv')

v_data = aggregate(cbind(Accuracy,Time.s)~Instance:Algorithm,data=v_data, FUN=mean)

v_dataSD = aggregate(cbind(Accuracy,Time.s)~Algorithm,data=v_data, FUN=sd)

v_nTime = calcN_tost2(alpha = 0.05,
            beta = 0.2,
            diff_mu = 1,
            tolmargin = min(v_dataSD$Time.s),
            s1 = v_dataSD$Time.s[1],
            s2 = v_dataSD$Time.s[2]
            )

v_nAcc = calcN_tost2(alpha = 0.05,
                      beta = 0.2,
                      diff_mu = 0.01,
                      tolmargin = 0.05,
                      s1 = v_dataSD$Accuracy[1],
                      s2 = v_dataSD$Accuracy[2]
                     )

v_n = ceiling(max(v_nTime, v_nAcc))


# sample data
v_data = readr::read_csv('1992-11-21_33_30.csv')
v_data = aggregate(cbind(Accuracy,Time.s)~Instance:Algorithm,data=v_data, FUN=mean)

splitInst = function (p_str){
  return (as.numeric(unlist(strsplit(p_str, 'Inst'))[2]))
}
v_data$Instance = unlist(lapply(v_data$Instance, splitInst))
v_data = v_data[order(v_data$Instance),]

# hypothesis test Time

v_diffTime = subset(v_data, Algorithm=='Proposed')$Time.s - subset(v_data, Algorithm=='Standard')$Time.s
v_tTestTime = t.test(v_diffTime,
                     conf.level = 0.05,
                     mu=0,
                     alternative = 'less'
                     )
v_pTime = v_tTestTime$p.value


# hypothesis test acc
v_diffAcc = subset(v_data, Algorithm=='Proposed')$Accuracy - subset(v_data, Algorithm=='Standard')$Accuracy
v_tTestAcc = t.test(v_diffAcc, 
                    mu = -0.05, 
                    conf.level = 0.05, 
                    alternative = 'greater'
                    )
v_pAcc = v_tTestAcc$p.value

## Hypothesis validation - Time

# Normality
qqPlot(v_diffTime)
v_shapiroTime = shapiro.test(v_diffTime)

# Independence
v_dwTime = dwtest(v_diffTime~1)
plot(v_diffTime, type='b')


## Hypothesis validation - Acc

# Normality
qqPlot(v_diffAcc)
v_shapiroAcc = shapiro.test(v_diffAcc)

# Independence
v_dwAcc = dwtest(v_diffAcc~1)
plot(v_diffAcc, type='b')
```

# 1. Descrição do Problema

O objetivo do experimento proposto é avaliar uma nova técnica proposta para simplificação de modelos em algoritmos de classificação, baseada em inferência estatística. Dessa forma, será realizada a comparação do algoritmo de classificação original e do método proposto. Para realizar o estudo, ambos serão executados em bases de dados da literatura.

Segundo os pesquisadores responsáveis pelo algoritmo proposto, este apresenta melhoria significativa em relação ao algoritmo original no tempo de execucão e não resulta em grandes perdas de desempenho, em termos de acurácia da classificação. Assim, busca-se responder:

1. O método proposto realmente apresenta ganhos em relação ao tempo de execução, quando comparado ao método padrão?
2. O método proposto não resulta em variações consideráveis de acurácia?

Para que sejam investigados os questionamentos acima são desejadas as seguintes características para os testes estatísticos:

```{r,results='show',warning=FALSE,echo=FALSE}
d_time <- 1.0
delta_ac <- 0.05
alpha <- 0.05
power <- 0.8
beta <- 1 - power
```

* Nível de significância: $\alpha = 0.05$;
* Tamanho de efeito de interesse prático para os ganhos de tempo: ${d^{\star}_{t}} = 1.0$;
* Margem de não-inferioridade para acurácia: $\delta_{acc}^{*} = 0.05$;
* Potência desejada: $\pi  = 0.8$.

# 2. Planejamento Experimental

Os dados experimentais utilizados foram obtidos através de simulação, por meio de um [aplicativo web](http://orcslab.cpdee.ufmg.br/3838/classdata). Os dados gerados informam o tempo necessário para a classificação (_Time.s_) e acurácia (_Accuracy_) de cada um dos algoritmos em cada instância e em cada execução. A data de nascimento do membro mais jovem da equipe (21/11/1992) é parâmetro utilizado como semente do gerador de números da simulação. O número de instâncias utilizadas e de execuções por instâncias deve ser selecionado no aplicativo.

O experimento envolve comparações entre métodos aplicados em diferentes instâncias de problemas de classificação. Conforme apresentado em [@Campelo2015-01], a variabilidade decorrente das características de cada problema de teste é uma forte fonte de variação espúria quando não considerada na análise dos resultados. Para eliminar a influência dessas variações, deve-se realizar o pareamento das medições por instância de teste.

Para isso, pode ser aplicado o teste de hipótese t pareado [@MontgomeryRunger2011], comparando as médias de ambos os algoritmos. No entanto, uma segunda alternativa é realizar o teste sobre as diferenças das médias dos algoritmos, de maneira que o efeito das instâncias se cancela. Dessa forma, define-se, para cada par j das n observações de médias $(\mu_{1j}, \mu_{2j})$, a diferença $d_j = \mu_{2j} - \mu_{1j}, \forall j \in (1,...,n)$.


## 2.1 Definição de Hipóteses

Para cada uma das questões levantadas no experimento, foi estabelecido um par de hipóteses.


## 2.1.1 Ganhos de Tempo

Definiu-se o teste de hipótese unilateral convencional. A hipótese nula é de que a diferença do tempo de execução médio do algoritmo proposto e do algoritmo original é nula, enquanto a hipótese alternativa estabelece que o algoritmo proposto é mais rápido que o original (diferença menor que zero). Esta formulação é apresentada abaixo, na qual $\mu_p^t$ representa a média de tempo do método proposto e $\mu_o^t$ a média de tempo do algoritmo original.

$$
\left\{\begin{array}{rc}
H_{0}: \mu_p^t - \mu_o^t = 0\\
H_{1}: \mu_p^t - \mu_o^t < 0
\end{array}\right.
$$

## 2.1.2 Não-inferioridade da Acurácia

Foi definido um teste de não-inferioridade do algoritmo proposto em relação ao atual. A  hipótese nula estabelece que a diferença entre a acurácia média do algoritmo proposto e do algoritmo orignal é maior que a margem de não-inferioridade estabelecida ($\delta_{acc}^{*}$), enquanto a enquanto a hipótese alternativa propõe que a diferença das acurácias é menor que essa margem. Sendo $\mu_p^{a}$ a média da acurácia do algoritmo proposto e $\mu_o^{a}$ a média da acurácia do algoritmo original, tem-se:

$$
\left\{\begin{array}{rc}
H_{0}: \mu_p^{a} - \mu_o^{a} = -\delta^{*}_{acc}\\
H_{1}: \mu_p^{a} - \mu_o^{a} > -\delta^{*}_{acc}\\
\end{array}\right.
$$

## 2.2 Número de Execuções por Instância

Para problemas com variáveis pareadas, cada par de médias avaliadas em diferentes instâncias constitui uma amostra independente [@Walker2011UnderstandingEA]. No entanto, é possível que, mesmo para observações coletadas sob condições homogêneas nas mesmas instâncias, exista o efeito de perturbações aleatórias [@MontgomeryRunger2011]. Uma forma de reduzir esse efeito é realizar repetidas execuções para cada instância e adotar como valor para a instância a média das diferentes execuções. 

Já foi demonstrado que aumentar o número de instâncias testadas apresenta uma melhoria maior sobre a potência dos testes do que aumentar o número de execuções em cada instância. Apesar disso, se o custo de execução não é impeditivo, é recomendável realizar pelo menos 30 execuções em cada instância [@Campelo2015-01]. Esse valor foi adotado nesse trabalho, uma vez que o custo da simulação não é significativo.


## 2.3 Definição do Tamanho Amostral

Para a realizar o cálculo do tamanho amostral necessário para a potência estabelecida, é necessário conhecer o desvio padrão de cada variável observada. Uma vez que não há disponível nenhum conhecimento histórico sobre os processos em questão, deve ser realizado um estudo piloto para determinar os desvios. 

Surge aí a necessidade de calcular o número de amostras para o estudo piloto. Inicialmente, utilizou-se a equação $n_{pilot}\approx 2\left(\frac{z_{\alpha_n/2}}{e_{n}}\right)^2$, em que $e_{n}$ representa o máximo erro relativo permitido para o tamanho da amostra. Estabelecendo $e_{n} = 0.1$, obtém-se $n_{pilot} = 800$. No entanto, essa equação pode resultar em tamanhos de estudo piloto maiores que o tamanho amostral necessário para o experimento [@Campelo2015-01]. 

Para contornar esse problema, um caminho alternativo foi tomado. O tamanho da amostra pode ser calculado pela equação:

$$n = 2 \left( \frac{\hat{\sigma}}{\delta^{\star}}\right)^{2}(t_{\alpha/2}+t_{\beta})^{2} \,, $$
e uma vez que, para o experimento do tempo o valor de ${d^{\star}_{t}} = \frac{\delta^{\star}}{\hat{\sigma}}$ é conhecido, é possível calcular o tamanho amostral mínimo necessário com a relação: 
$$n = 2 \left( \frac{1}{d^{\star}_t}\right)^{2}(t_{\alpha/2}+t_{\beta})^{2} \,,$$
em que $t_{\alpha/2}$ e $t_{\beta}$ são dependentes de $n$. Para solucionar esse problema, eles são substituídos por $z_{\alpha/2}$ e $z_{\beta}$ e a equação é testada iterativamente até convergência (implementação em anexo no arquivo  _calcN.R_). Dessa forma, foi encontrado o valor $n = 17$. Esse valor é significativamente menor que o valor $n_{pilot} = 800$ obtido anteriormente, o que é indicativo de tal era superestimado.

Com base nos resultados alcançados, foi realizado um estudo piloto com $17$ amostras. A partir desse estudo, foram determinados os desvios padrão de tempo e acurácia para o algoritmo proposto e original:

```{r,include=FALSE,results='hide',warning=FALSE,echo=FALSE}
v_dataPilot = readr::read_csv('pilot_1992-11-21_17_30.csv')

v_dataPilot = aggregate(cbind(Accuracy,Time.s)~Instance:Algorithm,data=v_data, FUN=mean)

v_dataPilotSD = aggregate(cbind(Accuracy,Time.s)~Algorithm,data=v_data, FUN=sd)

v_sdTimeProposed = v_dataPilotSD$Time.s[1]
v_sdTimeOriginal = v_dataPilotSD$Time.s[2]
v_sdAccProposed = v_dataPilotSD$Accuracy[1]
v_sdAccOriginal = v_dataPilotSD$Accuracy[2]
```

- $sd_p^t = `r v_sdTimeProposed`$
- $sd_o^t = `r v_sdTimeOriginal`$
- $sd_p^a = `r v_sdAccProposed`$
- $sd_o^a = `r v_sdAccOriginal`$

A partir desses valores, utilizou-se a fórmula em seguida (implementada no arquivo  _calcN_tost2.R_ [@Campelo2015-01]) para calcular o tamanho amostral mínimo para os experimentos de tempo e acurácia:

$$
n >= (t_{\alpha;\nu} + t_{(1-c)\beta;\nu})^2 
\left( \frac{\hat{\sigma}_1^2 + \hat{\sigma}_2^2}{\delta^{\star} - \Delta\mu^\star}\right)^2 \,.
$$

Utilizando esta equação determinou-se um tamanho amostral mínimo de $n = 33$ amostras para o teste de tempo e $n = 5$ amostras para o experimento com acurácia. O valor definitivo de amostras utilizado na coleta de dados foi então determinado como o máximo dos dois, 33.

## 2.4 Tratamento e Validação dos Dados

Considerando o experimento realizado, foi criada uma rotina para validação dos dados obtidos e identificação de erros. Para cada execução do algoritmo de classificação, as seguintes condições devem se aplicar:

1. Tempo de execução $> 0$
2. Acurácia $\in [0,1]$

Caso os valores de uma execução não atendam essas condições, ela é descartada.

# 3. Análise Estatística

## 3.1 Teste de Hipóteses

### 3.1.1 Ganho de Tempo

```{r,results='hide',warning=FALSE,echo=FALSE}
# hypothesis test Time
v_diffTime = subset(v_data, Algorithm=='Proposed')$Time.s - subset(v_data, Algorithm=='Standard')$Time.s
v_tTestTime = t.test(v_diffTime,
                     conf.level = 0.05,
                     mu=0,
                     alternative = 'less'
                     )
v_pTime = v_tTestTime$p.value
```

Realizando o teste de hipóteses apresentado na Seção 2.1.1, obtém-se $p = `r v_pTime`$. Dessa forma, é possível rejeitar a hipótese nula com um nível de confiança de $95\%$ e aceitar a hipótese a hipótese alternativa, que estabelece que o novo método proposto tem ganhos de tempo em relação ao método original, considerando um tamanho de efeito $d^\star = 1$.

Os bloxplots abaixo evidenciam a diferença entre as médias dos tempos de execução. Nota-se valores muito menores para o tempo de execução do algoritmo proposto. No boxplot da diferença, pode-se observar que a média é menor que zero, o que indica que o algoritmo proposto possui média de tempo de execução menor que a média do algoritmo original.

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=3, fig.width=3}
boxplot(subset(v_data, Algorithm=='Proposed')$Time.s, subset(v_data, Algorithm=='Standard')$Time.s, col = (c("blue", "red")),
main = "Tempo - Médias", names = c("Proposto", "Atual"),
xlab = "Algoritmo",
ylab = "Tempo de Execução")
```
```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=3, fig.width=3}
boxplot(subset(v_data, Algorithm=='Proposed')$Time.s - subset(v_data, Algorithm=='Standard')$Time.s, col = (c("green")),
main = "Tempo - Diferença", names = "P-A",
xlab = "Algoritmo",
ylab = "Diferença no Tempo de Execução")
```

### 3.1.2  Não-inferioridade da Acurácia

```{r,results='hide',warning=FALSE,echo=FALSE}
# hypothesis test acc
v_diffAcc = subset(v_data, Algorithm=='Proposed')$Accuracy - subset(v_data, Algorithm=='Standard')$Accuracy
v_tTestAcc = t.test(v_diffAcc, 
                    mu = -0.05, 
                    conf.level = 0.05, 
                    alternative = 'greater'
                    )
v_pAcc = v_tTestAcc$p.value
```

O teste de hipóteses proposto na Seção 2.1.2 apresenta $p = `r v_pAcc`$. Esse resultado não permite rejeitar a hipótese nula com um nível de confiança de $95\%$, considerando a margem de não-inferioridade $\delta_{acc}^{*} = 0.05$ estabelecida. Dessa forma, não é possível afirmar que o algoritmo proposto não apresenta acurácia inferior ao original.

O gráfico bloxplot referente ao experimento evidencia a diferença entre as médias das acurácias. Podemos ver que o intervalo de significância não está completamente acima da margem de não-inferioridade da acurácia dada. Portanto não foi possível estabelecer a não-inferioridade do algoritmo em relação à sua acurácia.

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=3, fig.width=3}
boxplot(subset(v_data, Algorithm=='Proposed')$Accuracy, subset(v_data, Algorithm=='Standard')$Accuracy, col = (c("blue", "red")),
main = "Acurácias - Médias", names = c("Proposto", "Atual"),
xlab = "Algoritmo",
ylab = "Acurácias")
```
```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=3, fig.width=3}
boxplot(subset(v_data, Algorithm=='Proposed')$Accuracy - subset(v_data, Algorithm=='Standard')$Accuracy, col = (c("green")),
main = "Acurácias - Diferença", names = c("Prp.-Std."),
xlab = "Algoritmo",
ylab = "Diferença de Acurácias")
abline(h = -0.05) 
```
## 3.2 Validação das Premissas
### 3.2.1 Tempo
#### Normalidade

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=3.5}
v_shapiroTime = shapiro.test(v_diffTime)
v_dwTime = dwtest(v_diffTime~1)
v_shapiroTimeP = v_shapiroTime$p.value
v_dwTimeP = v_dwTime$p.value
```

O QQPlot das diferenças de tempo entre os algoritmos é indicativo da normalidade de sua distribuição. Para confirmar esse resultado, é realizado o teste de Shapiro-Wilk. O teste apresenta $p = `r v_shapiroTimeP`$, de maneira que não é possível refutar a hipótese nula de que os dados apresentam distribuição normal.

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=3.5}
qqPlot(v_diffTime)
```
#### Independência

O plot dos valores ordenados de diferenças de tempo entre os algoritmos não apresenta nenhum indício de dependência temporal dos valores. O teste de autocorrelação serial Durbin-Wastson apresenta $p = `r v_dwTimeP`$, o que reforça a hipótese de que não há autocorrelação serial entre as amostras.

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=3.5}
plot(v_diffTime, type='b')
```
### Acurácia

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=3.5}
v_shapiroAcc = shapiro.test(v_diffAcc)
v_dwAcc = dwtest(v_diffAcc~1)
v_shapiroAccP = v_shapiroAcc$p.value
v_dwAccP = v_dwAcc$p.value
```

Os mesmos procedimentos são realizados para a acurácia. O teste de normalidade Shapiro-Wilk apresenta $p = `r v_shapiroAccP`$, enquanto o teste de autocorrelação serial Durbin-Watson apresenta $p = `r v_dwAccP`$. Nenhum dos resultados permite refutar as premissas de normalidade e independência. 


```{r,results='hide',warning=FALSE,echo=FALSE,fig.height=3.5}
qqPlot(v_diffAcc)
plot(v_diffAcc, type='b')
```
# 4. Discussão e Conclusões
Os testes de hipóteses realizados levam às seguintes conclusões:

1. É possível rejeitar a hipótese de que os algoritmos possuem tempos de execução equivalentes com grau de confiança de 95% para um tamanho de efeito $d^* = 1$. Esse resultado indica que o novo algoritmo apresenta tempos de execução melhores.
2. Não é possível refutar a hipótese de que a diferença de acurácia entre os algoritmos é maior que o tamanho de efeito $\delta^* = 0.05$ de 95%. Esse resultado não permite afirmar não inferioridade da acurácia do algoritmo proposto.

Vale notar que o teste de acurácia apresenta potência 1. Dessa forma, é seguro afirmar que não é possível estabelecer sua não inferioridade.

Os resultados indicam, portato, um trade-off entre os métodos avaliados. Enquanto o método proposto apresenta ganhos de tempo de execução de, pelo menos, um desvio padrão em relação ao anterior, não é possível garantir sua não inferioridade em relação a acurácia. A análise descritiva sugere que o método original possui maior acurácia. Assim, a utilização de cada método depende dos requisitos da aplicação. Se o tempo de execução for prioridade e uma ligeira perda na acurácia for aceitável, recomenda-se o método proposto. Se a acurácia da classificação é prioridade e tempos maiores são aceitáveis, recomenda-se o método original. 


# Referências