---
title: 'Estudo de Caso 02: Comparação entre Algoritmos de Classificação'
author: "Equipe 04"
date: "15 de maio de 2017"
output:
  pdf_document:
    fig_caption: yes
  word_document: default
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyfoot[CO,CE]{EEE933 - Planejamento e Análise de Experimentos}
- \fancyfoot[LE,RO]{\thepage}
csl: ieee.csl
bibliography: bibliography.bib
---  
Coordenador: Danny Tonidandel    
Relator: Alessandro Cardoso
Verificador:  Gustavo Vieira
Monitor: Bernardo Marques  

```{r setup,include=FALSE, results='hide',warning=FALSE,echo=FALSE}
  if (!require(readr, quietly = TRUE)){
    install.packages("readr")
  }
  if (!require(car, quietly = TRUE)){
    install.packages("car")
  }
  if (!require(lmtest, quietly = TRUE)){
    install.packages("lmtest")
  }
  source('calcN.R')
library(car)
library(lmtest)


# pilot size calc
v_nPilot = calcN_pilotD(p_alpha = 0.05,
                        p_beta = 0.2,
                        p_type = 'one-sided',
                        p_d = 1
                        )


# sample size calc
v_data = readr::read_csv('pilot_1992-11-21_17_30.csv')

v_data = aggregate(cbind(Accuracy,Time.s)~Instance:Algorithm,data=v_data, FUN=mean)

v_dataSD = aggregate(cbind(Accuracy,Time.s)~Algorithm,data=v_data, FUN=sd)

v_nTime = calcN_tost2(alpha = 0.05,
            beta = 0.2,
            diff_mu = 1,
            tolmargin = min(v_dataSD$Time.s),
            s1 = v_dataSD$Time.s[1],
            s2 = v_dataSD$Time.s[2]
            )

v_nAcc = calcN_tost2(alpha = 0.05,
                      beta = 0.2,
                      diff_mu = 0.01,
                      tolmargin = 0.05,
                      s1 = v_dataSD$Accuracy[1],
                      s2 = v_dataSD$Accuracy[2]
                     )

v_n = ceiling(max(v_nTime, v_nAcc))


# sample data
v_data = readr::read_csv('1992-11-21_33_30.csv')
v_data = aggregate(cbind(Accuracy,Time.s)~Instance:Algorithm,data=v_data, FUN=mean)

splitInst = function (p_str){
  return (as.numeric(unlist(strsplit(p_str, 'Inst'))[2]))
}
v_data$Instance = unlist(lapply(v_data$Instance, splitInst))
v_data = v_data[order(v_data$Instance),]

# hypothesis test Time

v_diffTime = subset(v_data, Algorithm=='Proposed')$Time.s - subset(v_data, Algorithm=='Standard')$Time.s
v_tTestTime = t.test(v_diffTime,
                     conf.level = 0.05,
                     mu=0,
                     alternative = 'less'
                     )
v_pTime = v_tTestTime$p.value


# hypothesis test acc
v_diffAcc = subset(v_data, Algorithm=='Proposed')$Accuracy - subset(v_data, Algorithm=='Standard')$Accuracy
v_tTestAcc = t.test(v_diffAcc, 
                    mu = -0.05, 
                    conf.level = 0.05, 
                    alternative = 'greater'
                    )
v_pAcc = v_tTestAcc$p.value

## Hypothesis validation - Time

# Normality
qqPlot(v_diffTime)
v_shapiroTime = shapiro.test(v_diffTime)

# Independence
v_dwTime = dwtest(v_diffTime~1)
plot(v_diffTime, type='b')


## Hypothesis validation - Acc

# Normality
qqPlot(v_diffAcc)
v_shapiroAcc = shapiro.test(v_diffAcc)

# Independence
v_dwAcc = dwtest(v_diffAcc~1)
plot(v_diffAcc, type='b')
```

# O Experimento

Este estudo de caso consiste na comparação de algoritmos de classificação em que um deles consiste no _padrão atual_ e o outro em um novo algoritmo proposto, que utilizada uma técnica de simplificação baseada em inferência estatística.

Segundo os pesquisadores responsáveis pelo algoritmo proposto, este apresenta uma melhora significativa frente ao padrão atual com relação ao tempo requerido para a classificação e que o essa nova abordagem não resulta em grandes perdas de desempenho em termos de acurácia da classificação. Assim, busca-se responder:

1. O método proposto realmente apresenta ganhos em relação ao tempo de execução, quando comparado ao método padrão? 

2. O método proposto não resulta em variações consideráveis de acurácia?

Para que sejam investigados os questionamentos acima são desejadas as seguintes características para os testes estatísticos:

```{r,results='show',warning=FALSE,echo=FALSE}
d_time <- 1.5
delta_ac <- 0.05
alpha <- 0.05
power <- 0.8
beta <- 1 - power
```

> Nível de significância: $\alpha = 0.05$;

> Tamanho de efeito de interesse prático para os ganhos de tempo: ${d^{\star}_{tempo}} = 1.5$;

> Margem de não-inferioridade para acurácia: $\delta_{acuracia}^{*} = 0.05$.

> Potência desejada: $\pi  = 0.8$;

# Planejamento experimental

Os dados experimentais para os testes foram gerados por meio de uma aplicação disponibilizada na web em $http://orcslab.cpdee.ufmg.br/3838/classdata$. Os dados são referentes ao tempo necessário para classificação (_Time.s_) e acurácia (_Accuracy_) por cada um dos algoritmos em cada instância e em cada execução. Para geração dos dados o grupo de trabalho deve fornecer a data de nascimento do membro mais jovem da equipe e selecionar um número de instâncias e execuções por instâncias.

Estes dados são apresentados conforme seleção de número de instâncias e número de repetições das mesmas. Segundo [@MontgomeryRunger2011] quando cada par de observação é coletado sobre condições homogêneas, ainda assim estas podem variar de um par para outro. Conforme apresentado em [@Campelo2015-01], a variabilidade devida aos diferentes problemas de teste é uma forte fonte de variação espúria que pode e deve ser controlada e que uma solução elegante para eliminar a influência deste inconveniente é o pareamento das medições por instância.

Conforme a apresentação das amostras, verificou-se a necessidade de efetuar os testes estatísticos com as amostras pareadas. Para [@MontgomeryRunger2011] o procedimento experimental mais adequado quando os dados são coletados aos pares é o _t-test pareado_. Para tal, seja ($X_{11}$, $X_{21}$), ($X_{12}$, $X_{22}$),..., ($X_{1n}$, $X_{2n}$) um conjunto de n observações pareadas onde assumimos que a média e a variância da população representada por $X_{1}$ são $\mu_{1}$ e $\sigma^{2}_{1}$, e a média e a variância da população representada por $X_{2}$ são $\mu_{2}$ e $\sigma^{2}_{2}$. Defini-se as diferenças entre cada par de observações como $D_{j}= X_{1j} - X_{2j}$, j= 1, 2, p,...n. Os $D_{j}$'s são assumidos como sendo normalmente distribuídos na média.

## Definicão de hipóteses

Os testes de hipótese elaborados são:

- Referente ao questionamento 1, definiu-se o teste de hipótese unilateral convencional, em que a hipótese nula é de que o algoritmo proposto apresenta tempo de execução similar ao algoritmo atual. Já a hipótese alternativa é a de que o algoritmo proposto é mais rápido que o padrão atual. Esta formulação é apresentada abaixo.

$$\left\{\begin{array}{rc}
H_{0}: \mu_{p{t}} - \mu_{a{t}} = 0\\
H_{1}: \mu_{p{t}} - \mu_{a{t}} < 0
\end{array}\right.$$

Os valores de $\mu_{p{t}}$ e $\mu_{a{t}}$ são as médias de tempo de execução dos algoritmos _proposto_ e _padrão atual_, respectivamente.

- Referente ao questionamento 2, definiu-se o teste de não-inferioridade, em que a hipótese nula afirma que o algoritmo proposto apresenta acurácia média inferior ao algoritmo atual. A hipótese alternativa afirma que o algoritmo proposto não apresenta acurácia média inferior ao padrão atual:

$$\left\{\begin{array}{rc}
H_{0}: \mu_{p{a}} - \mu_{a{a}} = -\delta^{*}_{acurácia}\\
H_{1}: \mu_{p{a}} - \mu_{a{a}} > -\delta^{*}_{acurácia}\\
\end{array}\right.$$

Os valores de $\mu_{p{a}}$ e $\mu_{a{a}}$ são os valores arbitrários de acurácia dos algoritmos _proposto_ e _padrão atual_ respectivamente e $\delta^{*}_{acurácia}\\$ é a margem de não-inferioridade para a acurácia.
<!-- Aqui eu mudei mup por mupt e mupa pra diferenciar a média dos tempo e de acurácia e fiz uma correçãozinha na hipótese nula do segundo caso --> 

## Tamanho amostral

No caso de amostras pareadas, entende-se por amostras, o números de instâncias conforme exposto por [@Walker2011UnderstandingEA], ou problemas a serem resolvidos pelos algoritmos. Outra consideração é o número de repetições a serem adotadas por instância. Para este estudo adotou-se empiricamente o valor de $30$ repetições por instância, seguindo recomendação expressas em [@Campelo2015-01].

Para a determinação do tamanho amostral foi realizado um _Estudo Piloto_, de forma a determinar uma estimativa inicial  para os testes atendendo aos parâmetros desejados, obtendo uma cardinalidade de $800$, para um erro relativo de $e_{n}=0.10$, em $n_{pilot}\approx 2\left(\frac{z_{\alpha_n/2}}{e_{n}}\right)^2$.
<!-- Pessoalmente, eu acho que podemos retirar esta parte, já que não nos levou a lugar algum esta equação, creio que esteja apenas alongando o relatório, uma vez que as 800 amostras calculadas não foram usadas posteriormente 
$$n_{pilot}\approx 2\left(\frac{z_{\alpha_n/2}}{e_{n}}\right)^2$$ -->

Por forne um número muito maior do que o número de amostras necessárias para um _Estudo Piloto_, a equipe decidiu por adotar um método iterativo. Como ${d^{\star}_{tempo}}$ é conhecido, ele foi utilizado para o cálculo, segundo a equação: 

$$n = 2 \left( \frac{1}{d^{\star}_{tempo}}\right)^{2}(t_{\alpha/2}+t_{\beta})^{2} \,.$$

Os valores de $t_{\alpha/2}$ e $t_{\beta}$ foram subtituidos para $z_{\alpha/2}$ e $z_{\beta}$ na equação anterior, considerando-se a prmeira iteração, de forma a fazê-los independetes de $n$. As iterações seguintes convergiram rapidamente para um valor de $17$ amostras, utilizadas no _Estudo Piloto_ conforme as entradas:

> Nascimento: 21/11/1992; 

> Número de instâncias de cada problema: $17$;

> Número de execuções: $30$;

```{r,results='hide',warning=FALSE,echo=FALSE}
head(v_data)
```
Por meio dos dados do _Estudo Piloto_ obteve-se o desvio padrão das amostras dos algoritmos, que foram, por sua vez, utilizados na obtenção do tamanho amostral mais adequado aos testes finais, Utilizando a função _calcN_tost2_ fornecida por [@Campelo2015-01].

```{r,results='hide',warning=FALSE,echo=FALSE}
v_nTime = calcN_tost2(alpha = 0.05,
            beta = 0.2,
            diff_mu = 1,
            tolmargin = min(v_dataSD$Time.s),
            s1 = v_dataSD$Time.s[1],
            s2 = v_dataSD$Time.s[2]
            )

v_nAcc = calcN_tost2(alpha = 0.05,
                      beta = 0.2,
                      diff_mu = 0.01,
                      tolmargin = 0.05,
                      s1 = v_dataSD$Accuracy[1],
                      s2 = v_dataSD$Accuracy[2]
                     )
```

Os testes definitivos serão feitos utilizando-se  $33$ instâncias de problemas, que permitirá, por sua vez, a geração de um novo conjunto de dados _1992-11-21_33_30.csv_, em que:
  
- Nascimento: 21/11/1992;

- Número de instâncias de cada problema: $33$;

- Número de execuções: $30$;

#Teste de Hipóteses
## Problema 1
Com o resultado do teste de hipóteses observa-se que não há evidências suficientes para se aceitar a hipótese nula (teste unilateral emparelhado), considerando-se a estatística gerada e o valor $p$ para o nível de significância e graus de liberdade definidos. Assim, conclui-se que o algoritmo proposto apresenta um desempenho melhor, em relação às médias dos tempos de execução, se comparado ao algoritmo padrão.
```{r,results='hide',warning=FALSE,echo=FALSE}
# hypothesis test Time
v_diffTime = subset(v_data, Algorithm=='Proposed')$Time.s - subset(v_data, Algorithm=='Standard')$Time.s
v_tTestTime = t.test(v_diffTime,
                     conf.level = 0.05,
                     mu=0,
                     alternative = 'less'
                     )
v_pTime = v_tTestTime$p.value
```

O gráfico bloxplot abaixo evidencia a diferença entre as médias dos tempos de execução. Podemos ver que a média é menor que zero, sugerindo que o algoritmo proposto possui média de tempo de execução menor que a média do algoritmo padrão.

```{r,results='hide',warning=FALSE,echo=FALSE}
boxplot(subset(v_data, Algorithm=='Proposed')$Time.s, subset(v_data, Algorithm=='Standard')$Time.s, col = (c("blue", "red")),
main = "Tempo - Médias", names = c("Proposed", "Standard"),
xlab = "Algoritmo",
ylab = "Tempo de Execução")
```
## Problema 2
O teste de hipóteses referente ao questionamento $2$ foi implementado e seu resultado indica que
que não existem evidências suficientes que levem à rejeição da hipótese nula, para os requisitos estabelecidos.

```{r,results='hide',warning=FALSE,echo=FALSE}
# hypothesis test acc
v_diffAcc = subset(v_data, Algorithm=='Proposed')$Accuracy - subset(v_data, Algorithm=='Standard')$Accuracy
v_tTestAcc = t.test(v_diffAcc, 
                    mu = -0.05, 
                    conf.level = 0.05, 
                    alternative = 'greater'
                    )
v_pAcc = v_tTestAcc$p.value
```

O gráfico bloxplot referente ao experimento 2 evidencia a diferença entre as médias das acurácias. Podemos ver que o intervalo de significância não está completamente acima da margem de não-inferioridade da acurácia dada. Por tanto não foi possível estabelecer a não-inferioridade do algoritmo em relação à sua acurácia.

```{r,results='hide',warning=FALSE,echo=FALSE}
boxplot(subset(v_data, Algorithm=='Proposed')$Accuracy, subset(v_data, Algorithm=='Standard')$Accuracy, col = (c("blue", "red")),
main = "Média das Acurácias", names = c("Proposed", "Standard"),
xlab = "Algoritmo",
ylab = "Acurácias")
```

# Validação dos testes
## Problema 1
A premissa de normalidade para o teste do questionamento 1 foi testada inicialmente de forma visual a partir do gráfico QQplot e pelo teste de Shapiro-Wilk. Ambos sugerem a normalidade dos dados.
```{r,results='hide',warning=FALSE,echo=TRUE}
## Hypothesis validation - Time
# Normality
qqPlot(v_diffTime)
v_shapiroTime = shapiro.test(v_diffTime)
v_dwTime = dwtest(v_diffTime~1)
```

## Problema 2
A premissas de normalidade e independência também sugerem que a amostra provêm de uma distribuição normal, com autocorrelação zero (independentes):

```{r,results='hide',warning=FALSE,echo=TRUE}
qqPlot(v_diffAcc)
v_shapiroAcc = shapiro.test(v_diffAcc)
v_dwAcc = dwtest(v_diffAcc~1)
```

# Conclusão

O grupo conseguiu realizar as análises da relação entre tempo de execução e acurácia entre os algoritmos padrão e alternativo com sucesso. Os resultados foram:

> 1. O método proposto apresenta ganhos significativos em termos de tempo de execução em relação ao método padrão.

> 2. O método proposto resulta em variações consideráveis de acurácia.

Pode-se afirmar que o método proposto tem ganhos significativos em termos dos tempos de execução. Em relação ao segundo resultado, como não foi possível rejeitar a hipótese nula com o nível de significância desejado, não é possível afirmar concluir que o método proposto é não-inferior ao método padrão.

Vale ainda ressaltar que o tamanho amostral necessário para as características desejadas do teste foram consideravelmente distoantes, a saber, $33$ para o primeiro teste e $4$ para o segundo. Foi então decidido fazer apenas um teste com o número mais alto de amostras, uma vez que isto não implicaria em perdas para nenhum dos casos, e não seria necessário fazer mais de uma "coleta". Um resultado disto foi que para o segundo teste a potência calculada para o teste foi $1$. Isto significa que a chance de ocorrer o erro do tipo _II_, que é a falha em rejeitar a hipótese nula sendo esta falsa, é $0$. Portanto, neste caso, as variações de acurácia são importantes.

# Referências